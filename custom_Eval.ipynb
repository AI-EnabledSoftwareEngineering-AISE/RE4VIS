{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffb8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "from pycocotools.coco import COCO\n",
    "# from torchvision.datasets.utils import download_url\n",
    "\n",
    "\n",
    "def coco_caption_eval(coco_gt_root, results_file):\n",
    "#     urls = {\n",
    "#         \"val\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val_gt.json\",\n",
    "#         \"test\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test_gt.json\",\n",
    "#     }\n",
    "#     filenames = {\n",
    "#         \"val\": \"coco_karpathy_val_gt.json\",\n",
    "#         \"test\": \"coco_karpathy_test_gt.json\",\n",
    "#     }\n",
    "\n",
    "#     download_url(urls[split], coco_gt_root)\n",
    "#     annotation_file = os.path.join(coco_gt_root, filenames[split])\n",
    "    annotation_file = coco_gt_root\n",
    "\n",
    "    # create coco object and coco_result object\n",
    "    coco = COCO(annotation_file)\n",
    "    coco_result = coco.loadRes(results_file)\n",
    "\n",
    "    # create coco_eval object by taking coco and coco_result\n",
    "    coco_eval = COCOEvalCap(coco, coco_result)\n",
    "\n",
    "    # evaluate on a subset of images by setting\n",
    "    # coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "    # please remove this line when evaluating the full validation set\n",
    "    # coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "\n",
    "    # evaluate results\n",
    "    # SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "    coco_eval.evaluate()\n",
    "\n",
    "    # print output evaluation scores\n",
    "    for metric, score in coco_eval.eval.items():\n",
    "        print(f\"{metric}: {score:.3f}\")\n",
    "\n",
    "    return coco_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a1a8fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17254 tokens at 118152.05 tokens per second.\n",
      "PTBTokenizer tokenized 9800 tokens at 93170.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "computing Bleu score...\n",
      "{'testlen': 8659, 'reflen': 16120, 'guess': [8659, 7524, 6389, 5408], 'correct': [3489, 1475, 782, 481]}\n",
      "ratio: 0.5371588089329692\n",
      "Bleu_1: 0.170\n",
      "Bleu_2: 0.119\n",
      "Bleu_3: 0.090\n",
      "Bleu_4: 0.072\n",
      "computing METEOR score...\n",
      "METEOR: 0.113\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.267\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.835\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [26.40 seconds]\n",
      "Error: Could not cache item to /home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"new york ny march 06 pedestrians walk along a manhattan street on march 6 2018 in new york city a new report by the governors highway safety association estimates the number of pedestrian deaths last year was 6000 nationwide a 33year high the report highlights a number of factors for the continued increase including distracted drivers using mobile devices and a larger number of cars on the road due to an improved economy despite an accident yesterday that took the lives of two small children in brooklyn new york city has been seeing a steady decline of pedestrian deaths since mayor bill de blasios vision zero initiative photo by spencer plattgetty images\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"illustration this illustration shows a high visibility crosswalk crossing a twolane road the twolane road extends from the lower left to the upper right corner of the illustration to the right of the crosswalk on street parking is present on both sides of the roadway on the right side of each lane approaching the crosswalk a pedestrian crossing warning sign with directional arrow plaque is present r16a stop here for pedestrians signs are also present in the center of the roadway within the illustration two inset images show close up photographs of the w112 pedestrian crossing warning sign with w167p directional arrow plaque and the r16a stop here for pedestrians sign respectively\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"tree pedestrian light architecture people sky road white traffic street window glass town building city cityscape downtown brown chicago facade blue street light colorful lane office building lights shadows children skyscrapers shops buildings roadway illinois infrastructure cars town square metropolis neighbourhood big city the skyscraper the centre of the door pedestrian crossing high houses urban area residential area human settlement helpfull state of illinois the city of chicago e commerce site the rebound in shafts\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.316 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 36.29 s\n",
      "SPICE: 0.168\n",
      "Bleu_1: 0.170\n",
      "Bleu_2: 0.119\n",
      "Bleu_3: 0.090\n",
      "Bleu_4: 0.072\n",
      "METEOR: 0.113\n",
      "ROUGE_L: 0.267\n",
      "CIDEr: 0.835\n",
      "SPICE: 0.168\n"
     ]
    }
   ],
   "source": [
    "gt = '/home/xtest/lavis/LAVIS/cache/coco_gt/coco_karpathy_val_gt.json'\n",
    "res = '/home/xtest/lavis/LAVIS/lavis/output/BLIP/Caption_coco/20221122111/result/val_epoch0.json'\n",
    "coco_eval = coco_caption_eval(gt, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe9ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat ~/.conda/envs/lavis/lib/python3.8/site-packages/pycocoevalcap/tokenizer/ptbtokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f2bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.17\" 2022-10-18\r\n",
      "OpenJDK Runtime Environment (build 11.0.17+8-post-Ubuntu-1ubuntu218.04)\r\n",
      "OpenJDK 64-Bit Server VM (build 11.0.17+8-post-Ubuntu-1ubuntu218.04, mixed mode, sharing)\r\n"
     ]
    }
   ],
   "source": [
    "! java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f2ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
