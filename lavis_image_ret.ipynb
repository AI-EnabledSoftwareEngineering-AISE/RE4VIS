{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75620a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xtest/lavis/LAVIS\n",
      "app\t\t\t    CODEOWNERS\t  lavis.egg-info  requirements-dev.txt\r\n",
      "assets\t\t\t    dataset_card  LICENSE.txt\t  run_scripts\r\n",
      "cache\t\t\t    docs\t  MANIFEST.in\t  SECURITY.md\r\n",
      "coco_karpathy_test_gt.json  evaluate.py   projects\t  setup.py\r\n",
      "coco_karpathy_val_gt.json   examples\t  __pycache__\t  tests\r\n",
      "CODE_OF_CONDUCT.md\t    lavis\t  README.md\t  train.py\r\n"
     ]
    }
   ],
   "source": [
    "%cd LAVIS\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c71549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2022-11-29 12:19:47,255 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2022-11-29 12:19:47,256 [INFO] {\n",
      "    \"amp\": false,\n",
      "    \"batch_size_eval\": 32,\n",
      "    \"batch_size_train\": 8,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": false,\n",
      "    \"gpu\": 0,\n",
      "    \"init_lr\": 2e-05,\n",
      "    \"k_test\": 256,\n",
      "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
      "    \"max_epoch\": 6,\n",
      "    \"min_lr\": 0,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Retrieval_COCO\",\n",
      "    \"rank\": 0,\n",
      "    \"resume_ckpt_path\": null,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"retrieval\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"train_splits\": [\n",
      "        \"train\"\n",
      "    ],\n",
      "    \"use_dist_eval_sampler\": false,\n",
      "    \"valid_splits\": [\n",
      "        \"val\",\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"weight_decay\": 0.04,\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2022-11-29 12:19:47,256 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2022-11-29 12:19:47,257 [INFO] \n",
      "======== coco_retrieval =======\n",
      "2022-11-29 12:19:47,257 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"/home/xtest/lavis/fat_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"/home/xtest/lavis/fat_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"/home/xtest/lavis/fat_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"image_size\": 384,\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"image_size\": 384,\n",
      "            \"name\": \"blip_image_train\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2022-11-29 12:19:47,257 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2022-11-29 12:19:47,258 [INFO] {\n",
      "    \"alpha\": 0.4,\n",
      "    \"arch\": \"blip_retrieval\",\n",
      "    \"embed_dim\": 256,\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_retrieval.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"coco\",\n",
      "    \"negative_all_rank\": true,\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"queue_size\": 57600,\n",
      "    \"vit_ckpt_layer\": 4,\n",
      "    \"vit_grad_ckpt\": true,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "2022-11-29 12:19:47,258 [INFO] Using existing file /home/xtest/lavis/LAVIS/lavis/../cache/coco/annotations/coco_karpathy_train.json.\n",
      "2022-11-29 12:19:47,258 [INFO] Using existing file /home/xtest/lavis/LAVIS/lavis/../cache/coco/annotations/coco_karpathy_val.json.\n",
      "2022-11-29 12:19:47,258 [INFO] Using existing file /home/xtest/lavis/LAVIS/lavis/../cache/coco/annotations/coco_karpathy_test.json.\n",
      "2022-11-29 12:19:47,259 [INFO] Building datasets...\n",
      "2022-11-29 12:19:56,998 [INFO] Missing keys []\n",
      "2022-11-29 12:19:56,998 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_retrieval.pth\n",
      "2022-11-29 12:19:57,016 [INFO] Start training\n",
      "2022-11-29 12:19:57,717 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2022-11-29 12:19:57,718 [INFO] Loaded 5678 records for train split from the dataset.\n",
      "2022-11-29 12:19:57,718 [INFO] Loaded 1135 records for val split from the dataset.\n",
      "2022-11-29 12:19:57,718 [INFO] Loaded 1299 records for test split from the dataset.\n",
      "2022-11-29 12:19:57,735 [INFO] Start training epoch 0, 354 iters per inner epoch.\n",
      "Train: data epoch: [0]  [  0/354]  eta: 0:14:50  lr: 0.000020  loss: 4.4379  time: 2.5159  data: 0.0000  max mem: 9710\n",
      "2022-11-29 12:20:00,258 [INFO] Reducer buckets have been rebuilt in this iteration.\n",
      "Train: data epoch: [0]  [ 50/354]  eta: 0:06:40  lr: 0.000020  loss: 3.8033  time: 1.3520  data: 0.0000  max mem: 12352\n",
      "Train: data epoch: [0]  [100/354]  eta: 0:08:56  lr: 0.000020  loss: 6.2641  time: 3.4587  data: 0.0000  max mem: 12352\n",
      "Train: data epoch: [0]  [150/354]  eta: 0:09:31  lr: 0.000020  loss: 4.3594  time: 4.4269  data: 0.0000  max mem: 12352\n",
      "Train: data epoch: [0]  [200/354]  eta: 0:08:22  lr: 0.000020  loss: 5.8387  time: 4.7788  data: 0.0000  max mem: 12353\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Train: data epoch: [0]  [250/354]  eta: 0:06:11  lr: 0.000020  loss: 5.6360  time: 4.8194  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [0]  [300/354]  eta: 0:03:26  lr: 0.000020  loss: 5.1702  time: 4.9996  data: 0.0000  max mem: 12353\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Train: data epoch: [0]  [350/354]  eta: 0:00:16  lr: 0.000020  loss: 4.8602  time: 5.0802  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [0]  [353/354]  eta: 0:00:04  lr: 0.000020  loss: 3.5750  time: 5.0603  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [0] Total time: 0:23:41 (4.0159 s / it)\n",
      "2022-11-29 12:43:39,422 [INFO] Averaged stats: lr: 0.0000  loss: 5.1216\n",
      "2022-11-29 12:43:39,425 [INFO] Evaluating on val.\n",
      "2022-11-29 12:43:39,443 [INFO] Computing features for evaluation...\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Evaluation:  [  0/568]  eta: 0:05:29    time: 0.5804  data: 0.0018  max mem: 12353\n",
      "Evaluation:  [ 50/568]  eta: 0:45:36    time: 5.2335  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/568]  eta: 0:40:37    time: 5.1333  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/568]  eta: 0:35:55    time: 5.0299  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/568]  eta: 0:31:22    time: 4.9904  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/568]  eta: 0:27:10    time: 5.2053  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/568]  eta: 0:22:58    time: 5.2441  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/568]  eta: 0:18:40    time: 5.0554  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/568]  eta: 0:14:21    time: 5.0007  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/568]  eta: 0:10:03    time: 4.9778  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [500/568]  eta: 0:05:46    time: 4.9342  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [550/568]  eta: 0:01:31    time: 4.8293  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [567/568]  eta: 0:00:05    time: 4.8450  data: 0.0000  max mem: 12353\n",
      "Evaluation: Total time: 0:48:04 (5.0779 s / it)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:  [  0/568]  eta: 0:03:11    time: 0.3368  data: 0.0014  max mem: 12353\n",
      "Evaluation:  [ 50/568]  eta: 0:41:45    time: 5.0469  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/568]  eta: 0:38:07    time: 4.9333  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/568]  eta: 0:34:09    time: 5.0202  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/568]  eta: 0:30:07    time: 4.7559  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/568]  eta: 0:26:01    time: 4.8957  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/568]  eta: 0:21:59    time: 4.8892  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/568]  eta: 0:17:52    time: 5.0068  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/568]  eta: 0:13:48    time: 5.0279  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/568]  eta: 0:09:41    time: 4.9779  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [500/568]  eta: 0:05:37    time: 5.4135  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [550/568]  eta: 0:01:30    time: 5.5052  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [567/568]  eta: 0:00:05    time: 5.3773  data: 0.0000  max mem: 12353\n",
      "Evaluation: Total time: 0:47:28 (5.0150 s / it)\n",
      "2022-11-29 14:21:19,108 [INFO] Evaluation time 1:37:39\n",
      "2022-11-29 14:21:19,250 [INFO] {'txt_r1': 48.19383259911894, 'txt_r5': 79.38325991189427, 'txt_r10': 87.22466960352423, 'txt_r_mean': 71.60058737151247, 'img_r1': 48.370044052863435, 'img_r5': 78.8546255506608, 'img_r10': 86.87224669603525, 'img_r_mean': 71.36563876651984, 'r_mean': 71.48311306901616, 'agg_metrics': 71.60058737151247}\n",
      "2022-11-29 14:21:19,277 [INFO] Saving checkpoint at epoch 0 to /home/xtest/lavis/LAVIS/lavis/output/BLIP/Retrieval_COCO/20221129121/checkpoint_best.pth.\n",
      "2022-11-29 14:21:24,459 [INFO] Evaluating on test.\n",
      "2022-11-29 14:21:24,477 [INFO] Computing features for evaluation...\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Evaluation:  [  0/650]  eta: 0:02:45    time: 0.2539  data: 0.0020  max mem: 12353\n",
      "Evaluation:  [ 50/650]  eta: 0:53:24    time: 5.3368  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/650]  eta: 0:47:54    time: 5.0214  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/650]  eta: 0:43:41    time: 5.2261  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/650]  eta: 0:39:25    time: 5.3225  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/650]  eta: 0:35:04    time: 5.2578  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/650]  eta: 0:30:39    time: 5.1662  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/650]  eta: 0:26:10    time: 5.2334  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/650]  eta: 0:21:44    time: 5.1253  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/650]  eta: 0:17:21    time: 5.1245  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [500/650]  eta: 0:12:59    time: 5.0009  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [550/650]  eta: 0:08:38    time: 5.1487  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [600/650]  eta: 0:04:18    time: 5.1330  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [649/650]  eta: 0:00:05    time: 5.2559  data: 0.0000  max mem: 12353\n",
      "Evaluation: Total time: 0:56:07 (5.1808 s / it)\n",
      "Evaluation:  [  0/650]  eta: 0:03:19    time: 0.3073  data: 0.0015  max mem: 12353\n",
      "Evaluation:  [ 50/650]  eta: 0:51:59    time: 5.2609  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/650]  eta: 0:47:22    time: 5.0326  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/650]  eta: 0:42:56    time: 5.2181  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/650]  eta: 0:38:37    time: 5.0485  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/650]  eta: 0:34:13    time: 5.1564  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/650]  eta: 0:29:55    time: 5.0409  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/650]  eta: 0:25:35    time: 5.1051  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/650]  eta: 0:21:23    time: 5.1139  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/650]  eta: 0:17:07    time: 5.1905  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [500/650]  eta: 0:12:51    time: 5.1658  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [550/650]  eta: 0:08:33    time: 5.0607  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [600/650]  eta: 0:04:17    time: 5.1637  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [649/650]  eta: 0:00:05    time: 5.0959  data: 0.0000  max mem: 12353\n",
      "Evaluation: Total time: 0:55:37 (5.1350 s / it)\n",
      "2022-11-29 16:15:36,502 [INFO] Evaluation time 1:54:12\n",
      "2022-11-29 16:15:36,708 [INFO] {'txt_r1': 46.88221709006928, 'txt_r5': 77.44418783679754, 'txt_r10': 86.9899923017706, 'txt_r_mean': 70.43879907621248, 'img_r1': 46.03541185527329, 'img_r5': 76.21247113163972, 'img_r10': 86.06620477290224, 'img_r_mean': 69.43802925327175, 'r_mean': 69.93841416474211, 'agg_metrics': 70.43879907621248}\n",
      "2022-11-29 16:15:36,709 [INFO] Start training\n",
      "2022-11-29 16:15:36,750 [INFO] Start training epoch 1, 354 iters per inner epoch.\n",
      "Train: data epoch: [1]  [  0/354]  eta: 0:31:12  lr: 0.000019  loss: 6.0964  time: 5.2888  data: 0.0000  max mem: 12353\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Train: data epoch: [1]  [ 50/354]  eta: 0:24:18  lr: 0.000019  loss: 4.6798  time: 4.8171  data: 0.0000  max mem: 12353\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Train: data epoch: [1]  [100/354]  eta: 0:20:18  lr: 0.000019  loss: 5.7410  time: 4.8244  data: 0.0000  max mem: 12353\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Train: data epoch: [1]  [150/354]  eta: 0:16:25  lr: 0.000019  loss: 5.3190  time: 4.9753  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1]  [200/354]  eta: 0:12:34  lr: 0.000019  loss: 5.7773  time: 5.1189  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1]  [250/354]  eta: 0:08:34  lr: 0.000019  loss: 5.4987  time: 5.1109  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1]  [300/354]  eta: 0:04:29  lr: 0.000019  loss: 5.6722  time: 5.1727  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1]  [350/354]  eta: 0:00:20  lr: 0.000019  loss: 6.0906  time: 4.9679  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1]  [353/354]  eta: 0:00:04  lr: 0.000019  loss: 5.4763  time: 4.9502  data: 0.0000  max mem: 12353\n",
      "Train: data epoch: [1] Total time: 0:29:29 (4.9994 s / it)\n",
      "2022-11-29 16:45:06,537 [INFO] Averaged stats: lr: 0.0000  loss: 5.4574\n",
      "2022-11-29 16:45:06,540 [INFO] Evaluating on val.\n",
      "2022-11-29 16:45:06,559 [INFO] Computing features for evaluation...\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/xtest/.conda/envs/lavis/lib/python3.8/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:  [  0/568]  eta: 0:02:09    time: 0.2274  data: 0.0017  max mem: 12353\n",
      "Evaluation:  [ 50/568]  eta: 0:45:36    time: 5.3430  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/568]  eta: 0:40:39    time: 5.0490  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/568]  eta: 0:36:08    time: 5.1452  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/568]  eta: 0:31:37    time: 5.0175  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/568]  eta: 0:27:13    time: 5.0810  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/568]  eta: 0:22:54    time: 4.9987  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/568]  eta: 0:18:35    time: 5.1325  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/568]  eta: 0:14:19    time: 5.0132  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/568]  eta: 0:10:01    time: 5.0372  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [500/568]  eta: 0:05:46    time: 5.1374  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [550/568]  eta: 0:01:31    time: 5.0243  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [567/568]  eta: 0:00:05    time: 5.0443  data: 0.0000  max mem: 12353\n",
      "Evaluation: Total time: 0:48:11 (5.0915 s / it)\n",
      "Evaluation:  [  0/568]  eta: 0:02:53    time: 0.3058  data: 0.0010  max mem: 12353\n",
      "Evaluation:  [ 50/568]  eta: 0:43:32    time: 5.0334  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [100/568]  eta: 0:39:23    time: 5.0668  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [150/568]  eta: 0:35:26    time: 5.2727  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [200/568]  eta: 0:31:26    time: 5.1471  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [250/568]  eta: 0:27:26    time: 5.4397  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [300/568]  eta: 0:23:12    time: 5.2474  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [350/568]  eta: 0:18:58    time: 5.3527  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [400/568]  eta: 0:14:39    time: 5.3506  data: 0.0000  max mem: 12353\n",
      "Evaluation:  [450/568]  eta: 0:10:19    time: 5.4846  data: 0.0000  max mem: 12353\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=2 train.py --cfg-path lavis/projects/blip/train/retrieval_coco_ft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b74d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
