{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xtest/projects/lavis_test/LAVIS\n",
      "app\t\t    evaluate.py  pyproject.toml\t\t    setup.py\n",
      "assets\t\t    examples\t README.md\t\t    tests\n",
      "CODE_OF_CONDUCT.md  lavis\t requirements.txt\t    train.py\n",
      "CODEOWNERS\t    LICENSE.txt  run_scripts\n",
      "dataset_card\t    MANIFEST.in  salesforce_lavis.egg-info\n",
      "docs\t\t    projects\t SECURITY.md\n"
     ]
    }
   ],
   "source": [
    "%cd LAVIS\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 01:15:47,381 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 01:15:47,382 [INFO] {\n",
      "    \"amp\": false,\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": false,\n",
      "    \"gpu\": 0,\n",
      "    \"init_lr\": 1e-05,\n",
      "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
      "    \"max_epoch\": 10,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"min_lr\": 0,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"resume_ckpt_path\": null,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"train_splits\": [\n",
      "        \"train\"\n",
      "    ],\n",
      "    \"valid_splits\": [\n",
      "        \"val\"\n",
      "    ],\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 01:15:47,382 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 01:15:47,382 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 01:15:47,383 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_caption\",\n",
      "            \"prompt\": \"a picture of \"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_image_train\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 01:15:47,383 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 01:15:47,383 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": false,\n",
      "    \"load_pretrained\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 01:15:47,383 [INFO] Building datasets...\n",
      "reshape position embedding from 196 to 576\n",
      "2023-09-23 01:15:53,112 [INFO] Missing keys []\n",
      "2023-09-23 01:15:53,112 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n",
      "2023-09-23 01:15:53,125 [INFO] Start training\n",
      "2023-09-23 01:15:53,365 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 01:15:53,365 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 01:15:53,365 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 01:15:53,365 [INFO] Loaded 42 records for test split from the dataset.\n",
      "2023-09-23 01:15:53,367 [INFO] number of trainable parameters: 223971644\n",
      "2023-09-23 01:15:53,368 [INFO] Start training epoch 0, 3 iters per inner epoch.\n",
      "Train: data epoch: [0]  [0/3]  eta: 0:00:20  lr: 0.000010  loss: 7.0376  loss_lm: 7.0376 (7.0376)  time: 6.7248  data: 0.0000  max mem: 21859\n",
      "2023-09-23 01:16:00,098 [INFO] Reducer buckets have been rebuilt in this iteration.\n",
      "Train: data epoch: [0]  [2/3]  eta: 0:00:03  lr: 0.000010  loss: 6.5206  loss_lm: 6.6928 (6.7503)  time: 3.0795  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [0] Total time: 0:00:09 (3.0802 s / it)\n",
      "2023-09-23 01:16:02,612 [INFO] Averaged stats: lr: 0.0000  loss: 6.8537  loss_lm: 6.8537\n",
      "2023-09-23 01:16:02,615 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3656  data: 3.7860  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3670 s / it)\n",
      "2023-09-23 01:16:07,992 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch0.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8670.50 tokens per second.\n",
      "PTBTokenizer tokenized 347 tokens at 4276.68 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 305, 'reflen': 900, 'guess': [305, 263, 221, 179], 'correct': [62, 8, 1, 0]}\n",
      "ratio: 0.3388888888885124\n",
      "Bleu_1: 0.029\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.093\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.061\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Threads( StanfordCoreNLP ) [9.780 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.54 s\n",
      "SPICE: 0.057\n",
      "Bleu_1: 0.029\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.093\n",
      "CIDEr: 0.061\n",
      "SPICE: 0.057\n",
      "2023-09-23 01:16:33,263 [INFO] Saving checkpoint at epoch 0 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth.\n",
      "2023-09-23 01:16:36,285 [INFO] Start training\n",
      "2023-09-23 01:16:36,295 [INFO] Start training epoch 1, 3 iters per inner epoch.\n",
      "Train: data epoch: [1]  [0/3]  eta: 0:00:20  lr: 0.000010  loss: 6.2956  loss_lm: 6.2956 (6.2956)  time: 6.7543  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [1]  [2/3]  eta: 0:00:03  lr: 0.000010  loss: 6.3487  loss_lm: 6.2956 (6.2786)  time: 3.0487  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1] Total time: 0:00:09 (3.0495 s / it)\n",
      "2023-09-23 01:16:45,444 [INFO] Averaged stats: lr: 0.0000  loss: 6.3022  loss_lm: 6.3022\n",
      "2023-09-23 01:16:45,447 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3020  data: 3.6962  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3041 s / it)\n",
      "2023-09-23 01:16:50,762 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch1.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8653.37 tokens per second.\n",
      "PTBTokenizer tokenized 382 tokens at 3728.92 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 333, 'reflen': 900, 'guess': [333, 291, 249, 208], 'correct': [61, 8, 0, 0]}\n",
      "ratio: 0.3699999999995889\n",
      "Bleu_1: 0.033\n",
      "Bleu_2: 0.013\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.026\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.086\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.056\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.391 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.98 s\n",
      "SPICE: 0.051\n",
      "Bleu_1: 0.033\n",
      "Bleu_2: 0.013\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.026\n",
      "ROUGE_L: 0.086\n",
      "CIDEr: 0.056\n",
      "SPICE: 0.051\n",
      "2023-09-23 01:17:16,682 [INFO] Start training\n",
      "2023-09-23 01:17:16,701 [INFO] Start training epoch 2, 3 iters per inner epoch.\n",
      "Train: data epoch: [2]  [0/3]  eta: 0:00:19  lr: 0.000009  loss: 6.1804  loss_lm: 6.1804 (6.1804)  time: 6.6035  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [2]  [2/3]  eta: 0:00:03  lr: 0.000009  loss: 5.9407  loss_lm: 5.9517 (6.0243)  time: 3.0150  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [2] Total time: 0:00:09 (3.0158 s / it)\n",
      "2023-09-23 01:17:25,751 [INFO] Averaged stats: lr: 0.0000  loss: 6.0866  loss_lm: 6.0866\n",
      "2023-09-23 01:17:25,753 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3116  data: 3.7226  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3138 s / it)\n",
      "2023-09-23 01:17:31,077 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch2.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8651.62 tokens per second.\n",
      "PTBTokenizer tokenized 375 tokens at 3659.29 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 325, 'reflen': 900, 'guess': [325, 283, 241, 200], 'correct': [64, 10, 0, 0]}\n",
      "ratio: 0.36111111111070987\n",
      "Bleu_1: 0.034\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.098\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.080\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [9.470 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.00 s\n",
      "SPICE: 0.064\n",
      "Bleu_1: 0.034\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.098\n",
      "CIDEr: 0.080\n",
      "SPICE: 0.064\n",
      "2023-09-23 01:17:57,067 [INFO] Saving checkpoint at epoch 2 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth.\n",
      "2023-09-23 01:18:08,261 [INFO] Start training\n",
      "2023-09-23 01:18:08,282 [INFO] Start training epoch 3, 3 iters per inner epoch.\n",
      "Train: data epoch: [3]  [0/3]  eta: 0:00:19  lr: 0.000008  loss: 6.2095  loss_lm: 6.2095 (6.2095)  time: 6.5211  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [3]  [2/3]  eta: 0:00:02  lr: 0.000008  loss: 5.8982  loss_lm: 5.9684 (6.0254)  time: 2.9688  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [3] Total time: 0:00:08 (2.9697 s / it)\n",
      "2023-09-23 01:18:17,194 [INFO] Averaged stats: lr: 0.0000  loss: 5.9589  loss_lm: 5.9589\n",
      "2023-09-23 01:18:17,196 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.4387  data: 3.8167  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.4408 s / it)\n",
      "2023-09-23 01:18:22,648 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch3.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8779.13 tokens per second.\n",
      "PTBTokenizer tokenized 434 tokens at 4213.95 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 385, 'reflen': 900, 'guess': [385, 343, 301, 260], 'correct': [73, 15, 0, 0]}\n",
      "ratio: 0.42777777777730247\n",
      "Bleu_1: 0.050\n",
      "Bleu_2: 0.024\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.031\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.097\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.063\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [9.184 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.96 s\n",
      "SPICE: 0.060\n",
      "Bleu_1: 0.050\n",
      "Bleu_2: 0.024\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.031\n",
      "ROUGE_L: 0.097\n",
      "CIDEr: 0.063\n",
      "SPICE: 0.060\n",
      "2023-09-23 01:18:45,411 [INFO] Start training\n",
      "2023-09-23 01:18:45,433 [INFO] Start training epoch 4, 3 iters per inner epoch.\n",
      "Train: data epoch: [4]  [0/3]  eta: 0:00:21  lr: 0.000007  loss: 5.9588  loss_lm: 5.9588 (5.9588)  time: 7.1551  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [4]  [2/3]  eta: 0:00:03  lr: 0.000007  loss: 5.7930  loss_lm: 5.8558 (5.8692)  time: 3.1962  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [4] Total time: 0:00:09 (3.1970 s / it)\n",
      "2023-09-23 01:18:55,026 [INFO] Averaged stats: lr: 0.0000  loss: 5.8442  loss_lm: 5.8442\n",
      "2023-09-23 01:18:55,029 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.4949  data: 3.9071  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.4968 s / it)\n",
      "2023-09-23 01:19:00,537 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch4.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8684.65 tokens per second.\n",
      "PTBTokenizer tokenized 388 tokens at 3791.65 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 339, 'reflen': 900, 'guess': [339, 297, 255, 214], 'correct': [65, 11, 0, 0]}\n",
      "ratio: 0.37666666666624815\n",
      "Bleu_1: 0.037\n",
      "Bleu_2: 0.016\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.098\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.071\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [8.933 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.01 s\n",
      "SPICE: 0.061\n",
      "Bleu_1: 0.037\n",
      "Bleu_2: 0.016\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.098\n",
      "CIDEr: 0.071\n",
      "SPICE: 0.061\n",
      "2023-09-23 01:19:24,763 [INFO] Start training\n",
      "2023-09-23 01:19:24,781 [INFO] Start training epoch 5, 3 iters per inner epoch.\n",
      "Train: data epoch: [5]  [0/3]  eta: 0:00:21  lr: 0.000005  loss: 5.6592  loss_lm: 5.6592 (5.6592)  time: 7.0013  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [5]  [2/3]  eta: 0:00:03  lr: 0.000005  loss: 5.6627  loss_lm: 5.6627 (5.6786)  time: 3.1489  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [5] Total time: 0:00:09 (3.1496 s / it)\n",
      "2023-09-23 01:19:34,234 [INFO] Averaged stats: lr: 0.0000  loss: 5.7445  loss_lm: 5.7445\n",
      "2023-09-23 01:19:34,237 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3890  data: 3.7723  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3906 s / it)\n",
      "2023-09-23 01:19:39,638 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch5.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8708.84 tokens per second.\n",
      "PTBTokenizer tokenized 379 tokens at 3576.79 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 329, 'reflen': 900, 'guess': [329, 287, 245, 205], 'correct': [67, 13, 0, 0]}\n",
      "ratio: 0.3655555555551494\n",
      "Bleu_1: 0.036\n",
      "Bleu_2: 0.017\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.030\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.102\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.069\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.616 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.63 s\n",
      "SPICE: 0.065\n",
      "Bleu_1: 0.036\n",
      "Bleu_2: 0.017\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.030\n",
      "ROUGE_L: 0.102\n",
      "CIDEr: 0.069\n",
      "SPICE: 0.065\n",
      "2023-09-23 01:20:06,338 [INFO] Start training\n",
      "2023-09-23 01:20:06,360 [INFO] Start training epoch 6, 3 iters per inner epoch.\n",
      "Train: data epoch: [6]  [0/3]  eta: 0:00:20  lr: 0.000003  loss: 5.7838  loss_lm: 5.7838 (5.7838)  time: 6.7540  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [6]  [2/3]  eta: 0:00:03  lr: 0.000003  loss: 5.4385  loss_lm: 5.7238 (5.6487)  time: 3.0774  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [6] Total time: 0:00:09 (3.0781 s / it)\n",
      "2023-09-23 01:20:15,599 [INFO] Averaged stats: lr: 0.0000  loss: 5.6961  loss_lm: 5.6961\n",
      "2023-09-23 01:20:15,602 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3335  data: 3.7489  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3352 s / it)\n",
      "2023-09-23 01:20:20,948 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch6.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8684.30 tokens per second.\n",
      "PTBTokenizer tokenized 370 tokens at 3625.52 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 320, 'reflen': 900, 'guess': [320, 278, 236, 197], 'correct': [73, 12, 0, 0]}\n",
      "ratio: 0.3555555555551605\n",
      "Bleu_1: 0.037\n",
      "Bleu_2: 0.016\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.031\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.108\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.079\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.4 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.87 s\n",
      "SPICE: 0.064\n",
      "Bleu_1: 0.037\n",
      "Bleu_2: 0.016\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.031\n",
      "ROUGE_L: 0.108\n",
      "CIDEr: 0.079\n",
      "SPICE: 0.064\n",
      "2023-09-23 01:20:45,853 [INFO] Start training\n",
      "2023-09-23 01:20:45,875 [INFO] Start training epoch 7, 3 iters per inner epoch.\n",
      "Train: data epoch: [7]  [0/3]  eta: 0:00:19  lr: 0.000002  loss: 5.6694  loss_lm: 5.6694 (5.6694)  time: 6.5522  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [7]  [2/3]  eta: 0:00:03  lr: 0.000002  loss: 5.7693  loss_lm: 5.7448 (5.7278)  time: 3.0058  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [7] Total time: 0:00:09 (3.0066 s / it)\n",
      "2023-09-23 01:20:54,898 [INFO] Averaged stats: lr: 0.0000  loss: 5.6543  loss_lm: 5.6543\n",
      "2023-09-23 01:20:54,901 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.4764  data: 3.8785  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.4792 s / it)\n",
      "2023-09-23 01:21:00,391 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch7.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8631.37 tokens per second.\n",
      "PTBTokenizer tokenized 368 tokens at 3539.11 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 325, 'reflen': 900, 'guess': [325, 283, 241, 202], 'correct': [72, 12, 0, 0]}\n",
      "ratio: 0.36111111111070987\n",
      "Bleu_1: 0.038\n",
      "Bleu_2: 0.017\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.030\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.105\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.078\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [9.76 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.69 s\n",
      "SPICE: 0.064\n",
      "Bleu_1: 0.038\n",
      "Bleu_2: 0.017\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.030\n",
      "ROUGE_L: 0.105\n",
      "CIDEr: 0.078\n",
      "SPICE: 0.064\n",
      "2023-09-23 01:21:23,534 [INFO] Start training\n",
      "2023-09-23 01:21:23,558 [INFO] Start training epoch 8, 3 iters per inner epoch.\n",
      "Train: data epoch: [8]  [0/3]  eta: 0:00:24  lr: 0.000001  loss: 5.5886  loss_lm: 5.5886 (5.5886)  time: 8.2957  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [8]  [2/3]  eta: 0:00:03  lr: 0.000001  loss: 5.6613  loss_lm: 5.5886 (5.5924)  time: 3.5931  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [8] Total time: 0:00:10 (3.5942 s / it)\n",
      "2023-09-23 01:21:34,344 [INFO] Averaged stats: lr: 0.0000  loss: 5.6448  loss_lm: 5.6448\n",
      "2023-09-23 01:21:34,347 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.5446  data: 3.9059  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.5467 s / it)\n",
      "2023-09-23 01:21:39,905 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch8.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8608.33 tokens per second.\n",
      "PTBTokenizer tokenized 374 tokens at 3619.16 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 331, 'reflen': 900, 'guess': [331, 289, 247, 208], 'correct': [81, 14, 0, 0]}\n",
      "ratio: 0.36777777777736914\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.020\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.032\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.107\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.075\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.883 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.84 s\n",
      "SPICE: 0.062\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.020\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.032\n",
      "ROUGE_L: 0.107\n",
      "CIDEr: 0.075\n",
      "SPICE: 0.062\n",
      "2023-09-23 01:22:05,701 [INFO] Start training\n",
      "2023-09-23 01:22:05,723 [INFO] Start training epoch 9, 3 iters per inner epoch.\n",
      "Train: data epoch: [9]  [0/3]  eta: 0:00:20  lr: 0.000000  loss: 5.6445  loss_lm: 5.6445 (5.6445)  time: 6.9184  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [9]  [2/3]  eta: 0:00:03  lr: 0.000000  loss: 5.6688  loss_lm: 5.6445 (5.6374)  time: 3.1215  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [9] Total time: 0:00:09 (3.1226 s / it)\n",
      "2023-09-23 01:22:15,095 [INFO] Averaged stats: lr: 0.0000  loss: 5.6359  loss_lm: 5.6359\n",
      "2023-09-23 01:22:15,098 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3884  data: 3.7791  max mem: 23586\n",
      "Evaluation Total time: 0:00:05 (5.3904 s / it)\n",
      "2023-09-23 01:22:20,499 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/val_epoch9.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 941 tokens at 8738.59 tokens per second.\n",
      "PTBTokenizer tokenized 374 tokens at 3593.78 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 331, 'reflen': 900, 'guess': [331, 289, 247, 208], 'correct': [81, 14, 0, 0]}\n",
      "ratio: 0.36777777777736914\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.020\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.032\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.107\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.075\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [8.872 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boulevard crossing in downtown 2007 boulevard crossing between spitalului street revoluţia din decembrie street and ion luca caragiale street in reşiţa romania cameras angle view is standing with the back to spitalului street română intersecţie în oraşul reşiţa din românia dintre strada spitalului strada revoluţia din decembrie şi strada ion luca caragiale unghiul de vedere a camerei este stând cu spatele la strada spitalului italiano incrocio tra tre strade della città di reşiţa nella romania spitalului revoluţia din decembrie ion luca caragiale langolo di guardare della macchina fotografica e stare con la strada spitalului indietro della visualizzatore\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.73 s\n",
      "SPICE: 0.062\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.020\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.032\n",
      "ROUGE_L: 0.107\n",
      "CIDEr: 0.075\n",
      "SPICE: 0.062\n",
      "2023-09-23 01:22:44,252 [INFO] Loading checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.6423  data: 3.0516  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.6440 s / it)\n",
      "2023-09-23 01:22:50,980 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1034 tokens at 9377.69 tokens per second.\n",
      "PTBTokenizer tokenized 369 tokens at 3569.66 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 324, 'reflen': 993, 'guess': [324, 282, 240, 199], 'correct': [67, 11, 2, 0]}\n",
      "ratio: 0.3262839879150793\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.114\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.169\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [22.557 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 28.83 s\n",
      "SPICE: 0.067\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.114\n",
      "CIDEr: 0.169\n",
      "SPICE: 0.067\n",
      "2023-09-23 01:23:28,766 [INFO] Training time 0:07:35\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=2 train.py --cfg-path lavis/projects/blip/train/caption_coco_ft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 01:32:37,077 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 01:32:37,078 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 01:32:37,078 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 01:32:37,078 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 01:32:37,078 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 01:32:37,078 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 01:32:37,079 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 01:32:37,079 [INFO] Building datasets...\n",
      "2023-09-23 01:32:42,239 [INFO] Missing keys []\n",
      "2023-09-23 01:32:42,239 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth\n",
      "2023-09-23 01:32:42,253 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 01:32:42,253 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 01:32:42,253 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 01:32:42,253 [INFO] Loaded 42 records for test split from the dataset.\n",
      "2023-09-23 01:32:42,254 [INFO] Empty train splits.\n",
      "2023-09-23 01:32:42,254 [INFO] Empty train splits.\n",
      "2023-09-23 01:32:42,254 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:06    time: 6.0685  data: 2.7854  max mem: 2572\n",
      "Evaluation Total time: 0:00:06 (6.0696 s / it)\n",
      "2023-09-23 01:32:48,454 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923013/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1034 tokens at 9556.89 tokens per second.\n",
      "PTBTokenizer tokenized 369 tokens at 3767.57 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 324, 'reflen': 993, 'guess': [324, 282, 240, 199], 'correct': [67, 11, 2, 0]}\n",
      "ratio: 0.3262839879150793\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.114\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.169\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [22.484 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 29.76 s\n",
      "SPICE: 0.067\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.114\n",
      "CIDEr: 0.169\n",
      "SPICE: 0.067\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation path: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations\n",
    "# ann file: coco_karpathy_test.json\n",
    "# gt path: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt\n",
    "# test gt file: coco_karpathy_test_gt.json\n",
    "\n",
    "# test first topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 01:50:00,149 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 01:50:00,149 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 01:50:00,149 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 01:50:00,150 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 01:50:00,150 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 01:50:00,150 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 01:50:00,150 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 01:50:00,151 [INFO] Building datasets...\n",
      "2023-09-23 01:50:04,861 [INFO] Missing keys []\n",
      "2023-09-23 01:50:04,862 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-23 01:50:04,878 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 01:50:04,878 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 01:50:04,878 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 01:50:04,878 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-23 01:50:04,878 [INFO] Empty train splits.\n",
      "2023-09-23 01:50:04,878 [INFO] Empty train splits.\n",
      "2023-09-23 01:50:04,878 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.3976  data: 1.0046  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.3987 s / it)\n",
      "2023-09-23 01:50:08,475 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923014/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 588 tokens at 5587.44 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 1637.29 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 143, 'reflen': 574, 'guess': [143, 128, 113, 98], 'correct': [28, 2, 0, 0]}\n",
      "ratio: 0.24912891986019317\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.015\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.071\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.060\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [22.542 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 28.38 s\n",
      "SPICE: 0.006\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.015\n",
      "ROUGE_L: 0.071\n",
      "CIDEr: 0.060\n",
      "SPICE: 0.006\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation path: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations\n",
    "# ann file: coco_karpathy_test.json\n",
    "# gt path: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt\n",
    "# test gt file: coco_karpathy_test_gt.json\n",
    "\n",
    "# test second topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 02:00:21,149 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 02:00:21,151 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 02:00:21,151 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 02:00:21,151 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 02:00:21,151 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 02:00:21,151 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 02:00:21,151 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 02:00:21,152 [INFO] Building datasets...\n",
      "2023-09-23 02:00:26,122 [INFO] Missing keys []\n",
      "2023-09-23 02:00:26,122 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-23 02:00:26,140 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 02:00:26,140 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 02:00:26,140 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 02:00:26,140 [INFO] Loaded 18 records for test split from the dataset.\n",
      "2023-09-23 02:00:26,140 [INFO] Empty train splits.\n",
      "2023-09-23 02:00:26,140 [INFO] Empty train splits.\n",
      "2023-09-23 02:00:26,140 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.7335  data: 2.2607  max mem: 2085\n",
      "Evaluation Total time: 0:00:04 (4.7346 s / it)\n",
      "2023-09-23 02:00:31,043 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923020/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 418 tokens at 3976.94 tokens per second.\n",
      "PTBTokenizer tokenized 205 tokens at 2092.42 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 188, 'reflen': 401, 'guess': [188, 170, 152, 134], 'correct': [19, 0, 0, 0]}\n",
      "ratio: 0.46882793017339447\n",
      "Bleu_1: 0.033\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.014\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.050\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.033\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [21.941 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 27.98 s\n",
      "SPICE: 0.027\n",
      "Bleu_1: 0.033\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.014\n",
      "ROUGE_L: 0.050\n",
      "CIDEr: 0.033\n",
      "SPICE: 0.027\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation path: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations\n",
    "# ann file: coco_karpathy_test.json\n",
    "# gt path: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt\n",
    "# test gt file: coco_karpathy_test_gt.json\n",
    "\n",
    "# test third topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 0, world 2): env://\n",
      "| distributed init (rank 1, world 2): env://\n",
      "2023-09-23 02:06:37,288 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 02:06:37,289 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 02:06:37,289 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 02:06:37,289 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 02:06:37,290 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 02:06:37,290 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 02:06:37,290 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 02:06:37,291 [INFO] Building datasets...\n",
      "2023-09-23 02:06:42,360 [INFO] Missing keys []\n",
      "2023-09-23 02:06:42,360 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923011/checkpoint_best.pth\n",
      "2023-09-23 02:06:42,374 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 02:06:42,375 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 02:06:42,375 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 02:06:42,375 [INFO] Loaded 14 records for test split from the dataset.\n",
      "2023-09-23 02:06:42,375 [INFO] Empty train splits.\n",
      "2023-09-23 02:06:42,375 [INFO] Empty train splits.\n",
      "2023-09-23 02:06:42,375 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.7689  data: 1.4163  max mem: 2019\n",
      "Evaluation Total time: 0:00:03 (3.7700 s / it)\n",
      "2023-09-23 02:06:46,900 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923020/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 274 tokens at 2796.93 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 990.17 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 82, 'reflen': 261, 'guess': [82, 68, 54, 41], 'correct': [18, 5, 1, 0]}\n",
      "ratio: 0.31417624520952425\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.008\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.033\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.133\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.237\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 1.093 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.008\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.033\n",
      "ROUGE_L: 0.133\n",
      "CIDEr: 0.237\n",
      "SPICE: 0.096\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 0, world 2): env://\n",
      "| distributed init (rank 1, world 2): env://\n",
      "2023-09-23 16:20:30,787 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 16:20:30,788 [INFO] {\n",
      "    \"amp\": false,\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": false,\n",
      "    \"gpu\": 0,\n",
      "    \"init_lr\": 1e-05,\n",
      "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
      "    \"max_epoch\": 10,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"min_lr\": 0,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"resume_ckpt_path\": null,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"train_splits\": [\n",
      "        \"train\"\n",
      "    ],\n",
      "    \"valid_splits\": [\n",
      "        \"val\"\n",
      "    ],\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 16:20:30,788 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 16:20:30,788 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 16:20:30,789 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_caption\",\n",
      "            \"prompt\": \"a picture of \"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_image_train\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 16:20:30,789 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 16:20:30,789 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": false,\n",
      "    \"load_pretrained\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 16:20:30,789 [INFO] Building datasets...\n",
      "reshape position embedding from 196 to 576\n",
      "2023-09-23 16:20:37,588 [INFO] Missing keys []\n",
      "2023-09-23 16:20:37,588 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n",
      "2023-09-23 16:20:37,600 [INFO] Start training\n",
      "2023-09-23 16:20:37,706 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 16:20:37,706 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 16:20:37,706 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 16:20:37,706 [INFO] Loaded 42 records for test split from the dataset.\n",
      "2023-09-23 16:20:37,708 [INFO] number of trainable parameters: 223971644\n",
      "2023-09-23 16:20:37,708 [INFO] Start training epoch 0, 3 iters per inner epoch.\n",
      "Train: data epoch: [0]  [0/3]  eta: 0:00:19  lr: 0.000010  loss: 7.1461  loss_lm: 7.1461 (7.1461)  time: 6.5646  data: 0.0000  max mem: 21859\n",
      "2023-09-23 16:20:44,279 [INFO] Reducer buckets have been rebuilt in this iteration.\n",
      "Train: data epoch: [0]  [2/3]  eta: 0:00:03  lr: 0.000010  loss: 6.7332  loss_lm: 6.7332 (6.8001)  time: 3.0063  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [0] Total time: 0:00:09 (3.0069 s / it)\n",
      "2023-09-23 16:20:46,731 [INFO] Averaged stats: lr: 0.0000  loss: 6.7299  loss_lm: 6.7299\n",
      "2023-09-23 16:20:46,734 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1252  data: 2.5126  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1266 s / it)\n",
      "2023-09-23 16:20:50,906 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch0.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9559.18 tokens per second.\n",
      "PTBTokenizer tokenized 307 tokens at 3012.87 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 264, 'reflen': 1010, 'guess': [264, 222, 180, 141], 'correct': [84, 18, 5, 3]}\n",
      "ratio: 0.2613861386136026\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.004\n",
      "computing METEOR score...\n",
      "METEOR: 0.034\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.148\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Threads( StanfordCoreNLP ) [10.425 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.140 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 17.32 s\n",
      "SPICE: 0.082\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.004\n",
      "METEOR: 0.034\n",
      "ROUGE_L: 0.148\n",
      "CIDEr: 0.294\n",
      "SPICE: 0.082\n",
      "2023-09-23 16:21:16,784 [INFO] Saving checkpoint at epoch 0 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/checkpoint_best.pth.\n",
      "2023-09-23 16:21:19,897 [INFO] Start training\n",
      "2023-09-23 16:21:19,905 [INFO] Start training epoch 1, 3 iters per inner epoch.\n",
      "Train: data epoch: [1]  [0/3]  eta: 0:00:19  lr: 0.000010  loss: 6.0567  loss_lm: 6.0567 (6.0567)  time: 6.3423  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1]  [2/3]  eta: 0:00:02  lr: 0.000010  loss: 6.2411  loss_lm: 6.1224 (6.1401)  time: 2.9190  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1] Total time: 0:00:08 (2.9197 s / it)\n",
      "2023-09-23 16:21:28,665 [INFO] Averaged stats: lr: 0.0000  loss: 6.2001  loss_lm: 6.2001\n",
      "2023-09-23 16:21:28,668 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0511  data: 2.4354  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0526 s / it)\n",
      "2023-09-23 16:21:32,823 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch1.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9672.14 tokens per second.\n",
      "PTBTokenizer tokenized 335 tokens at 3304.60 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 287, 'reflen': 1010, 'guess': [287, 245, 203, 164], 'correct': [93, 22, 7, 3]}\n",
      "ratio: 0.2841584158413028\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.008\n",
      "Bleu_4: 0.005\n",
      "computing METEOR score...\n",
      "METEOR: 0.036\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.161\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.628 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.599 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.79 s\n",
      "SPICE: 0.079\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.008\n",
      "Bleu_4: 0.005\n",
      "METEOR: 0.036\n",
      "ROUGE_L: 0.161\n",
      "CIDEr: 0.341\n",
      "SPICE: 0.079\n",
      "2023-09-23 16:21:59,611 [INFO] Saving checkpoint at epoch 1 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/checkpoint_best.pth.\n",
      "2023-09-23 16:22:10,467 [INFO] Start training\n",
      "2023-09-23 16:22:10,487 [INFO] Start training epoch 2, 3 iters per inner epoch.\n",
      "Train: data epoch: [2]  [0/3]  eta: 0:00:19  lr: 0.000009  loss: 5.9317  loss_lm: 5.9317 (5.9317)  time: 6.6150  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [2]  [2/3]  eta: 0:00:03  lr: 0.000009  loss: 5.6910  loss_lm: 5.8692 (5.8306)  time: 3.0247  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [2] Total time: 0:00:09 (3.0254 s / it)\n",
      "2023-09-23 16:22:19,566 [INFO] Averaged stats: lr: 0.0000  loss: 5.9811  loss_lm: 5.9811\n",
      "2023-09-23 16:22:19,569 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0833  data: 2.5126  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0849 s / it)\n",
      "2023-09-23 16:22:23,890 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch2.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9661.69 tokens per second.\n",
      "PTBTokenizer tokenized 396 tokens at 3859.96 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 350, 'reflen': 1010, 'guess': [350, 308, 266, 224], 'correct': [100, 22, 7, 3]}\n",
      "ratio: 0.34653465346500345\n",
      "Bleu_1: 0.043\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.039\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.151\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Threads( StanfordCoreNLP ) [11.568 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.749 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 19.82 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.043\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.039\n",
      "ROUGE_L: 0.151\n",
      "CIDEr: 0.286\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:22:53,078 [INFO] Start training\n",
      "2023-09-23 16:22:53,099 [INFO] Start training epoch 3, 3 iters per inner epoch.\n",
      "Train: data epoch: [3]  [0/3]  eta: 0:00:17  lr: 0.000008  loss: 5.7418  loss_lm: 5.7418 (5.7418)  time: 5.9295  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [3]  [2/3]  eta: 0:00:02  lr: 0.000008  loss: 5.8643  loss_lm: 5.8643 (5.9324)  time: 2.7917  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [3] Total time: 0:00:08 (2.7925 s / it)\n",
      "2023-09-23 16:23:01,480 [INFO] Averaged stats: lr: 0.0000  loss: 5.8683  loss_lm: 5.8683\n",
      "2023-09-23 16:23:01,483 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1473  data: 2.5470  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1491 s / it)\n",
      "2023-09-23 16:23:05,803 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch3.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9478.11 tokens per second.\n",
      "PTBTokenizer tokenized 386 tokens at 3727.65 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 341, 'reflen': 1010, 'guess': [341, 299, 257, 216], 'correct': [108, 24, 8, 3]}\n",
      "ratio: 0.33762376237590336\n",
      "Bleu_1: 0.045\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.013\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.043\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.166\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.862 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.381 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 17.61 s\n",
      "SPICE: 0.104\n",
      "Bleu_1: 0.045\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.013\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.043\n",
      "ROUGE_L: 0.166\n",
      "CIDEr: 0.318\n",
      "SPICE: 0.104\n",
      "2023-09-23 16:23:32,302 [INFO] Start training\n",
      "2023-09-23 16:23:32,323 [INFO] Start training epoch 4, 3 iters per inner epoch.\n",
      "Train: data epoch: [4]  [0/3]  eta: 0:00:18  lr: 0.000007  loss: 5.4592  loss_lm: 5.4592 (5.4592)  time: 6.0633  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [4]  [2/3]  eta: 0:00:02  lr: 0.000007  loss: 5.7149  loss_lm: 5.7149 (5.6650)  time: 2.8362  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [4] Total time: 0:00:08 (2.8368 s / it)\n",
      "2023-09-23 16:23:40,838 [INFO] Averaged stats: lr: 0.0000  loss: 5.7316  loss_lm: 5.7316\n",
      "2023-09-23 16:23:40,841 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1438  data: 2.5239  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1456 s / it)\n",
      "2023-09-23 16:23:45,094 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch4.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9510.22 tokens per second.\n",
      "PTBTokenizer tokenized 394 tokens at 3828.13 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 350, 'reflen': 1010, 'guess': [350, 308, 266, 225], 'correct': [111, 24, 7, 3]}\n",
      "ratio: 0.34653465346500345\n",
      "Bleu_1: 0.048\n",
      "Bleu_2: 0.024\n",
      "Bleu_3: 0.013\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.169\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.392\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [9.928 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.570 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 17.17 s\n",
      "SPICE: 0.100\n",
      "Bleu_1: 0.048\n",
      "Bleu_2: 0.024\n",
      "Bleu_3: 0.013\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.169\n",
      "CIDEr: 0.392\n",
      "SPICE: 0.100\n",
      "2023-09-23 16:24:13,465 [INFO] Saving checkpoint at epoch 4 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/checkpoint_best.pth.\n",
      "2023-09-23 16:24:24,150 [INFO] Start training\n",
      "2023-09-23 16:24:24,169 [INFO] Start training epoch 5, 3 iters per inner epoch.\n",
      "Train: data epoch: [5]  [0/3]  eta: 0:00:19  lr: 0.000005  loss: 5.6742  loss_lm: 5.6742 (5.6742)  time: 6.3727  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [5]  [2/3]  eta: 0:00:02  lr: 0.000005  loss: 5.6412  loss_lm: 5.6563 (5.6572)  time: 2.9778  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [5] Total time: 0:00:08 (2.9784 s / it)\n",
      "2023-09-23 16:24:33,109 [INFO] Averaged stats: lr: 0.0000  loss: 5.6843  loss_lm: 5.6843\n",
      "2023-09-23 16:24:33,112 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0337  data: 2.4462  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0352 s / it)\n",
      "2023-09-23 16:24:37,401 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch5.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9683.03 tokens per second.\n",
      "PTBTokenizer tokenized 418 tokens at 3990.80 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 374, 'reflen': 1010, 'guess': [374, 332, 290, 249], 'correct': [111, 23, 7, 3]}\n",
      "ratio: 0.3702970297026037\n",
      "Bleu_1: 0.054\n",
      "Bleu_2: 0.026\n",
      "Bleu_3: 0.014\n",
      "Bleu_4: 0.009\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.160\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.281\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [10.460 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.345 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.46 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.054\n",
      "Bleu_2: 0.026\n",
      "Bleu_3: 0.014\n",
      "Bleu_4: 0.009\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.160\n",
      "CIDEr: 0.281\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:25:03,565 [INFO] Start training\n",
      "2023-09-23 16:25:03,586 [INFO] Start training epoch 6, 3 iters per inner epoch.\n",
      "Train: data epoch: [6]  [0/3]  eta: 0:00:18  lr: 0.000003  loss: 5.5778  loss_lm: 5.5778 (5.5778)  time: 6.1329  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [6]  [2/3]  eta: 0:00:02  lr: 0.000003  loss: 5.8557  loss_lm: 5.5778 (5.6534)  time: 2.8698  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [6] Total time: 0:00:08 (2.8704 s / it)\n",
      "2023-09-23 16:25:12,201 [INFO] Averaged stats: lr: 0.0000  loss: 5.6094  loss_lm: 5.6094\n",
      "2023-09-23 16:25:12,204 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1250  data: 2.5166  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1266 s / it)\n",
      "2023-09-23 16:25:16,447 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch6.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9534.17 tokens per second.\n",
      "PTBTokenizer tokenized 382 tokens at 3721.52 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 339, 'reflen': 1010, 'guess': [339, 297, 255, 214], 'correct': [108, 24, 7, 3]}\n",
      "ratio: 0.3356435643561033\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.165\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [11.284 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.452 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 18.79 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.165\n",
      "CIDEr: 0.286\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:25:44,426 [INFO] Start training\n",
      "2023-09-23 16:25:44,448 [INFO] Start training epoch 7, 3 iters per inner epoch.\n",
      "Train: data epoch: [7]  [0/3]  eta: 0:00:19  lr: 0.000002  loss: 5.4568  loss_lm: 5.4568 (5.4568)  time: 6.5303  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [7]  [2/3]  eta: 0:00:02  lr: 0.000002  loss: 5.5744  loss_lm: 5.4568 (5.4878)  time: 2.9965  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [7] Total time: 0:00:08 (2.9972 s / it)\n",
      "2023-09-23 16:25:53,443 [INFO] Averaged stats: lr: 0.0000  loss: 5.5810  loss_lm: 5.5810\n",
      "2023-09-23 16:25:53,446 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1588  data: 2.5661  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1604 s / it)\n",
      "2023-09-23 16:25:57,699 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch7.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9539.39 tokens per second.\n",
      "PTBTokenizer tokenized 382 tokens at 3725.85 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 339, 'reflen': 1010, 'guess': [339, 297, 255, 214], 'correct': [108, 24, 7, 3]}\n",
      "ratio: 0.3356435643561033\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.165\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.605 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.50 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.044\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.165\n",
      "CIDEr: 0.286\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:26:22,855 [INFO] Start training\n",
      "2023-09-23 16:26:22,877 [INFO] Start training epoch 8, 3 iters per inner epoch.\n",
      "Train: data epoch: [8]  [0/3]  eta: 0:00:18  lr: 0.000001  loss: 5.3915  loss_lm: 5.3915 (5.3915)  time: 6.0314  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [8]  [2/3]  eta: 0:00:02  lr: 0.000001  loss: 5.5182  loss_lm: 5.5182 (5.5580)  time: 2.8367  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [8] Total time: 0:00:08 (2.8373 s / it)\n",
      "2023-09-23 16:26:31,393 [INFO] Averaged stats: lr: 0.0000  loss: 5.5453  loss_lm: 5.5453\n",
      "2023-09-23 16:26:31,396 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1017  data: 2.4860  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1032 s / it)\n",
      "2023-09-23 16:26:35,780 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch8.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9532.85 tokens per second.\n",
      "PTBTokenizer tokenized 377 tokens at 3658.12 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 334, 'reflen': 1010, 'guess': [334, 292, 250, 209], 'correct': [107, 24, 7, 3]}\n",
      "ratio: 0.3306930693066033\n",
      "Bleu_1: 0.042\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.166\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.587 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.78 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.042\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.166\n",
      "CIDEr: 0.286\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:27:00,792 [INFO] Start training\n",
      "2023-09-23 16:27:00,813 [INFO] Start training epoch 9, 3 iters per inner epoch.\n",
      "Train: data epoch: [9]  [0/3]  eta: 0:00:17  lr: 0.000000  loss: 5.4378  loss_lm: 5.4378 (5.4378)  time: 5.9134  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [9]  [2/3]  eta: 0:00:02  lr: 0.000000  loss: 5.7667  loss_lm: 5.4378 (5.5443)  time: 2.7846  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [9] Total time: 0:00:08 (2.7852 s / it)\n",
      "2023-09-23 16:27:09,173 [INFO] Averaged stats: lr: 0.0000  loss: 5.5379  loss_lm: 5.5379\n",
      "2023-09-23 16:27:09,175 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0400  data: 2.4457  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0415 s / it)\n",
      "2023-09-23 16:27:13,440 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/val_epoch9.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1051 tokens at 9603.01 tokens per second.\n",
      "PTBTokenizer tokenized 379 tokens at 3687.02 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 336, 'reflen': 1010, 'guess': [336, 294, 252, 211], 'correct': [107, 23, 7, 3]}\n",
      "ratio: 0.3326732673264033\n",
      "Bleu_1: 0.043\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "computing METEOR score...\n",
      "METEOR: 0.044\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.165\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.283\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.891 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the m2 motorway and the raillink crossing the medway between cuxton and borstal the nashenden valley on the other bank is typical of kentish downland scenery the m2 junction 2 entry roundabout on the a228 and the m2 motorway bridge and the channel tunnel rail link bridge crossing the river medway viewed from merralls shaw ranscombe farm cuxton on the far bank we see borstal fort borstal and the motorway snaking up the nashenden valley while the rail link proceeds in a more direct line on the roundabout is a bus run by arriva serving the 151 route chatham to west malling camera location5116022160534160n 016028160012160eview this and other nearby images on openstreetmap google earth\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 17.95 s\n",
      "SPICE: 0.096\n",
      "Bleu_1: 0.043\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.165\n",
      "CIDEr: 0.283\n",
      "SPICE: 0.096\n",
      "2023-09-23 16:27:41,580 [INFO] Loading checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/checkpoint_best.pth.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.6128  data: 2.9910  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.6146 s / it)\n",
      "2023-09-23 16:27:48,142 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923162/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1034 tokens at 9410.54 tokens per second.\n",
      "PTBTokenizer tokenized 372 tokens at 3594.45 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 330, 'reflen': 993, 'guess': [330, 288, 246, 204], 'correct': [63, 9, 1, 0]}\n",
      "ratio: 0.33232628398758074\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.024\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.090\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.091\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [23.161 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.18 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 30.65 s\n",
      "SPICE: 0.037\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.024\n",
      "ROUGE_L: 0.090\n",
      "CIDEr: 0.091\n",
      "SPICE: 0.037\n",
      "2023-09-23 16:28:29,236 [INFO] Training time 0:07:51\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=2 train.py --cfg-path lavis/projects/blip/train/caption_coco_ft.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 16:34:26,817 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 16:34:26,818 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 16:34:26,818 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 16:34:26,818 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 16:34:26,818 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 16:34:26,818 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 16:34:26,819 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 16:34:26,819 [INFO] Building datasets...\n",
      "2023-09-23 16:34:31,963 [INFO] Missing keys []\n",
      "2023-09-23 16:34:31,964 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\n",
      "2023-09-23 16:34:31,980 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 16:34:31,980 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 16:34:31,980 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 16:34:31,980 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-23 16:34:31,980 [INFO] Empty train splits.\n",
      "2023-09-23 16:34:31,980 [INFO] Empty train splits.\n",
      "2023-09-23 16:34:31,980 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.4262  data: 0.9561  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.4273 s / it)\n",
      "2023-09-23 16:34:35,571 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923163/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 588 tokens at 5504.65 tokens per second.\n",
      "PTBTokenizer tokenized 137 tokens at 1432.97 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 122, 'reflen': 574, 'guess': [122, 107, 92, 77], 'correct': [31, 2, 0, 0]}\n",
      "ratio: 0.21254355400659836\n",
      "Bleu_1: 0.006\n",
      "Bleu_2: 0.002\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.023\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.086\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.112\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [23.436 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 29.75 s\n",
      "SPICE: 0.040\n",
      "Bleu_1: 0.006\n",
      "Bleu_2: 0.002\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.023\n",
      "ROUGE_L: 0.086\n",
      "CIDEr: 0.112\n",
      "SPICE: 0.040\n"
     ]
    }
   ],
   "source": [
    "# test first topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 16:38:37,022 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 16:38:37,023 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 16:38:37,023 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 16:38:37,023 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 16:38:37,024 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 16:38:37,024 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 16:38:37,024 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 16:38:37,025 [INFO] Building datasets...\n",
      "2023-09-23 16:38:42,089 [INFO] Missing keys []\n",
      "2023-09-23 16:38:42,089 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\n",
      "2023-09-23 16:38:42,102 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 16:38:42,102 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 16:38:42,102 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 16:38:42,102 [INFO] Loaded 18 records for test split from the dataset.\n",
      "2023-09-23 16:38:42,102 [INFO] Empty train splits.\n",
      "2023-09-23 16:38:42,102 [INFO] Empty train splits.\n",
      "2023-09-23 16:38:42,102 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.8441  data: 2.3131  max mem: 2085\n",
      "Evaluation Total time: 0:00:04 (4.8453 s / it)\n",
      "2023-09-23 16:38:47,147 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923163/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 418 tokens at 4013.44 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 1538.12 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 133, 'reflen': 401, 'guess': [133, 115, 97, 79], 'correct': [26, 4, 0, 0]}\n",
      "ratio: 0.33167082294181627\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.021\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.096\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.051\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [21.905 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 28.06 s\n",
      "SPICE: 0.046\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.021\n",
      "ROUGE_L: 0.096\n",
      "CIDEr: 0.051\n",
      "SPICE: 0.046\n"
     ]
    }
   ],
   "source": [
    "# test second topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 16:41:21,014 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 16:41:21,016 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 16:41:21,016 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 16:41:21,016 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 16:41:21,016 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 16:41:21,017 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 16:41:21,017 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 16:41:21,017 [INFO] Building datasets...\n",
      "2023-09-23 16:41:26,131 [INFO] Missing keys []\n",
      "2023-09-23 16:41:26,131 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\n",
      "2023-09-23 16:41:26,149 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 16:41:26,149 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 16:41:26,149 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 16:41:26,149 [INFO] Loaded 14 records for test split from the dataset.\n",
      "2023-09-23 16:41:26,149 [INFO] Empty train splits.\n",
      "2023-09-23 16:41:26,149 [INFO] Empty train splits.\n",
      "2023-09-23 16:41:26,149 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.9443  data: 1.5288  max mem: 2019\n",
      "Evaluation Total time: 0:00:03 (3.9455 s / it)\n",
      "2023-09-23 16:41:30,269 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923164/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 274 tokens at 2664.96 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 1296.84 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 112, 'reflen': 261, 'guess': [112, 98, 84, 70], 'correct': [17, 4, 1, 0]}\n",
      "ratio: 0.42911877394471604\n",
      "Bleu_1: 0.040\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.011\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.026\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.088\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.128\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 1.078 s\n",
      "SPICE: 0.018\n",
      "Bleu_1: 0.040\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.011\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.026\n",
      "ROUGE_L: 0.088\n",
      "CIDEr: 0.128\n",
      "SPICE: 0.018\n"
     ]
    }
   ],
   "source": [
    "# test second topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-23 16:46:17,158 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-23 16:46:17,160 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-23 16:46:17,160 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-23 16:46:17,160 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-23 16:46:17,160 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-23 16:46:17,161 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-23 16:46:17,161 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-23 16:46:17,161 [INFO] Building datasets...\n",
      "2023-09-23 16:46:22,235 [INFO] Missing keys []\n",
      "2023-09-23 16:46:22,235 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/finetune_random/checkpoint_best.pth\n",
      "2023-09-23 16:46:22,249 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-23 16:46:22,249 [INFO] Loaded 191 records for train split from the dataset.\n",
      "2023-09-23 16:46:22,249 [INFO] Loaded 42 records for val split from the dataset.\n",
      "2023-09-23 16:46:22,249 [INFO] Loaded 42 records for test split from the dataset.\n",
      "2023-09-23 16:46:22,249 [INFO] Empty train splits.\n",
      "2023-09-23 16:46:22,249 [INFO] Empty train splits.\n",
      "2023-09-23 16:46:22,249 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:06    time: 6.1975  data: 2.8853  max mem: 2572\n",
      "Evaluation Total time: 0:00:06 (6.1987 s / it)\n",
      "2023-09-23 16:46:28,675 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230923164/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1034 tokens at 9508.29 tokens per second.\n",
      "PTBTokenizer tokenized 372 tokens at 3744.06 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 330, 'reflen': 993, 'guess': [330, 288, 246, 204], 'correct': [63, 9, 1, 0]}\n",
      "ratio: 0.33232628398758074\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.024\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.090\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.091\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [23.549 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the technical equpment of a bicycle and pedestrian counter next to a cycle path using an infrared sensor in burlington this bicycle amp pedestrian counter manufactured by ecocounter is capable of collecting bidirectional bicycle amp pedestrian traffic ie the direction of travel of each pedestrian bicycle et al is logged the devices sensor detects infrared radiation emitted by each person who passes by it the sensors narrow profile further enables it to count two or more people following closely to one another the device will function at temperatures between 40 deg f up to 122 degf this device can not distinguish between bicycles or pedestrians a common factor reducing the level of observation ie undercounting of this data is lack of the pyroelectric sensors ability to detect adjacenttravelling bicyclists or pedestrians see page 10 in the paper effectiveness of a commercially available automated pedestrian counting device in urban environments comparison with manual counts 22 jul 2007\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"a 512512 lattice with density of 33 after 64000 iterations traffic is at a disordered intermediate phase a lattice for the wbihammiddletonlevine traffic model after 64000 iterations the lattice is 512 by 512 with a traffic density of 33 the red cars and blue cars take turns to move the red ones only move rightwards and the blue ones move downwards every time all the cars of the same colour try to move one step if there is no car in front of it the initial position before running is shown in filebml x 512 y 512 p 33 iterated 0png the graph of mobility versus time mobility is the number of cars that can move in a particular turn is shown at filebml x 512 y 512 p 33 mobilitypng this was created with c source code is located at wuserpurpy pupplebml\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"playback of selfdriving system data at 13 seconds before impact distances shown in meters washington may 24 2018 this uber selfdriving system data playback from the fatal march 18 2018 crash of an uber technologies inc test vehicle in tempe arizona shows when at 13 seconds before impact the system determined emergency braking was needed to mitigate a collision the yellow bands depict meters ahead of the vehicle the orange lines show the center of mapped travel lanes the purple area shows the path of the vehicle and the green line depicts the center of that path\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 30.38 s\n",
      "SPICE: 0.037\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.024\n",
      "ROUGE_L: 0.090\n",
      "CIDEr: 0.091\n",
      "SPICE: 0.037\n"
     ]
    }
   ],
   "source": [
    "# test second topic\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_3topic.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_3topic.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = [ {\"Bleu_1\": 0.009613123006944611, \"Bleu_2\": 0.002715585715476971, \"Bleu_3\": 1.4742247488158496e-08, \"Bleu_4\": 3.5594006938592466e-11, \"METEOR\": 0.014754249962504783, \"ROUGE_L\": 0.07093603854502294, \"CIDEr\": 0.0600478956731983, \"SPICE\": 0.005581637976004173},\n",
    "{\"Bleu_1\": 0.032549876415994654, \"Bleu_2\": 2.4832875286468453e-10, \"Bleu_3\": 5.074438652067186e-13, \"Bleu_4\": 2.3672994832824757e-14, \"METEOR\": 0.013822514801158873, \"ROUGE_L\": 0.049920492880017875, \"CIDEr\": 0.033026820747432774, \"SPICE\": 0.026758447043534764},\n",
    "{\"Bleu_1\": 0.0362209042674112, \"Bleu_2\": 3.364600826282051e-10, \"Bleu_3\": 7.385566094208971e-13, \"Bleu_4\": 3.591777621254285e-14, \"METEOR\": 0.023594168575767245, \"ROUGE_L\": 0.05910889813272208, \"CIDEr\": 0.08879320048096288, \"SPICE\": 0.039177489177489186},\n",
    "{\"Bleu_1\": 0.03140068375840798, \"Bleu_2\": 0.006436709573692018, \"Bleu_3\": 3.13572627671035e-08, \"Bleu_4\": 7.162295145801328e-11, \"METEOR\": 0.01856332545400822, \"ROUGE_L\": 0.062459148506459825, \"CIDEr\": 0.06471092395727814, \"SPICE\": 0.025197759746499557}\n",
    "]\n",
    "\n",
    "# Create a DataFrame with 'v1', 'v2', 'v3', 'all' as the index\n",
    "index = ['Variant1', 'Variant2', 'variant3', 'all']\n",
    "base_df = pd.DataFrame(base_data, index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.009613</td>\n",
       "      <td>2.715586e-03</td>\n",
       "      <td>1.474225e-08</td>\n",
       "      <td>3.559401e-11</td>\n",
       "      <td>0.014754</td>\n",
       "      <td>0.070936</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.005582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.032550</td>\n",
       "      <td>2.483288e-10</td>\n",
       "      <td>5.074439e-13</td>\n",
       "      <td>2.367299e-14</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.049920</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.026758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.036221</td>\n",
       "      <td>3.364601e-10</td>\n",
       "      <td>7.385566e-13</td>\n",
       "      <td>3.591778e-14</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.088793</td>\n",
       "      <td>0.039177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.031401</td>\n",
       "      <td>6.436710e-03</td>\n",
       "      <td>3.135726e-08</td>\n",
       "      <td>7.162295e-11</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>0.062459</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>0.025198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1        Bleu_2        Bleu_3        Bleu_4    METEOR  \\\n",
       "Variant1  0.009613  2.715586e-03  1.474225e-08  3.559401e-11  0.014754   \n",
       "Variant2  0.032550  2.483288e-10  5.074439e-13  2.367299e-14  0.013823   \n",
       "variant3  0.036221  3.364601e-10  7.385566e-13  3.591778e-14  0.023594   \n",
       "all       0.031401  6.436710e-03  3.135726e-08  7.162295e-11  0.018563   \n",
       "\n",
       "           ROUGE_L     CIDEr     SPICE  \n",
       "Variant1  0.070936  0.060048  0.005582  \n",
       "Variant2  0.049920  0.033027  0.026758  \n",
       "variant3  0.059109  0.088793  0.039177  \n",
       "all       0.062459  0.064711  0.025198  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_by_cadee_data = [ \n",
    "    {\"Bleu_1\": 0.004337749515387003, \"Bleu_2\": 0.0008952235699853606, \"Bleu_3\": 5.584884708160166e-09, \"Bleu_4\": 1.4643192971593505e-11, \"METEOR\": 0.02110675830805572, \"ROUGE_L\": 0.09140924860656353, \"CIDEr\": 0.11914087884311816, \"SPICE\": 0.05591343091343091},\n",
    "    {\"Bleu_1\": 0.04118342542054832, \"Bleu_2\": 0.017854013003868553, \"Bleu_3\": 0.00827030715371226, \"Bleu_4\": 1.0413422485269536e-06, \"METEOR\": 0.030564211961888715, \"ROUGE_L\": 0.11207122442577394, \"CIDEr\": 0.12196748045422237, \"SPICE\": 0.05631436464769798},\n",
    "    {\"Bleu_1\": 0.02474147438358407, \"Bleu_2\": 0.014319465116471128, \"Bleu_3\": 0.007536023634347256, \"Bleu_4\": 1.0414836479275402e-06, \"METEOR\": 0.03280916185182163, \"ROUGE_L\": 0.13276892104754606, \"CIDEr\": 0.2369770861465684, \"SPICE\": 0.09584750566893425},\n",
    "    {\"Bleu_1\": 0.026229626851552976, \"Bleu_2\": 0.011391974507247273, \"Bleu_3\": 0.005157347094888179, \"Bleu_4\": 5.437785614809762e-07, \"METEOR\": 0.02875961602493655, \"ROUGE_L\": 0.11448261667704364, \"CIDEr\": 0.1693283280259555, \"SPICE\": 0.06733484501341644}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>5.584885e-09</td>\n",
       "      <td>1.464319e-11</td>\n",
       "      <td>0.021107</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.055913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>8.270307e-03</td>\n",
       "      <td>1.041342e-06</td>\n",
       "      <td>0.030564</td>\n",
       "      <td>0.112071</td>\n",
       "      <td>0.121967</td>\n",
       "      <td>0.056314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.024741</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>7.536024e-03</td>\n",
       "      <td>1.041484e-06</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.132769</td>\n",
       "      <td>0.236977</td>\n",
       "      <td>0.095848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>5.157347e-03</td>\n",
       "      <td>5.437786e-07</td>\n",
       "      <td>0.028760</td>\n",
       "      <td>0.114483</td>\n",
       "      <td>0.169328</td>\n",
       "      <td>0.067335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1    Bleu_2        Bleu_3        Bleu_4    METEOR   ROUGE_L  \\\n",
       "Variant1  0.004338  0.000895  5.584885e-09  1.464319e-11  0.021107  0.091409   \n",
       "Variant2  0.041183  0.017854  8.270307e-03  1.041342e-06  0.030564  0.112071   \n",
       "variant3  0.024741  0.014319  7.536024e-03  1.041484e-06  0.032809  0.132769   \n",
       "all       0.026230  0.011392  5.157347e-03  5.437786e-07  0.028760  0.114483   \n",
       "\n",
       "             CIDEr     SPICE  \n",
       "Variant1  0.119141  0.055913  \n",
       "Variant2  0.121967  0.056314  \n",
       "variant3  0.236977  0.095848  \n",
       "all       0.169328  0.067335  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with 'v1', 'v2', 'v3', 'all' as the index\n",
    "index = index = ['Variant1', 'Variant2', 'variant3', 'all']\n",
    "cadee_data_df = pd.DataFrame(fine_by_cadee_data, index=index)\n",
    "cadee_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_by_random_data = [ \n",
    "    {\"Bleu_1\": 0.006251387292583912, \"Bleu_2\": 0.0016955030799119348, \"Bleu_3\": 9.160685224948332e-09, \"Bleu_4\": 2.226214077049635e-11, \"METEOR\": 0.02250648618080888, \"ROUGE_L\": 0.08576731407338194, \"CIDEr\": 0.11194829547859118, \"SPICE\": 0.04027995098583334},\n",
    "    {\"Bleu_1\": 0.026061655464178966, \"Bleu_2\": 0.010993151700742134, \"Bleu_3\": 5.4968978526898016e-08, \"Bleu_4\": 1.2939024946927896e-10, \"METEOR\": 0.02094850041251234, \"ROUGE_L\": 0.09604747182073331, \"CIDEr\": 0.05084308426904701, \"SPICE\": 0.04649911816578483},\n",
    "    {\"Bleu_1\": 0.04012953548146247, \"Bleu_2\": 0.020809691458788863, \"Bleu_3\": 0.01108736666170332, \"Bleu_4\": 1.5062779060729865e-06, \"METEOR\": 0.025798365168279207, \"ROUGE_L\": 0.08757575133833143, \"CIDEr\": 0.1278961187967634, \"SPICE\": 0.01805449452508276},\n",
    "    {\"Bleu_1\": 0.025602920879083696, \"Bleu_2\": 0.010358603748632584, \"Bleu_3\": 0.0038818916789758523, \"Bleu_4\": 4.4283378167036e-07, \"METEOR\": 0.024347706048723713, \"ROUGE_L\": 0.09019684798812329, \"CIDEr\": 0.09110190789496737, \"SPICE\": 0.036919356709272676}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>9.160685e-09</td>\n",
       "      <td>2.226214e-11</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>0.085767</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.040280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>5.496898e-08</td>\n",
       "      <td>1.293902e-10</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.096047</td>\n",
       "      <td>0.050843</td>\n",
       "      <td>0.046499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.040130</td>\n",
       "      <td>0.020810</td>\n",
       "      <td>1.108737e-02</td>\n",
       "      <td>1.506278e-06</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>0.087576</td>\n",
       "      <td>0.127896</td>\n",
       "      <td>0.018054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>3.881892e-03</td>\n",
       "      <td>4.428338e-07</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1    Bleu_2        Bleu_3        Bleu_4    METEOR   ROUGE_L  \\\n",
       "Variant1  0.006251  0.001696  9.160685e-09  2.226214e-11  0.022506  0.085767   \n",
       "Variant2  0.026062  0.010993  5.496898e-08  1.293902e-10  0.020949  0.096047   \n",
       "variant3  0.040130  0.020810  1.108737e-02  1.506278e-06  0.025798  0.087576   \n",
       "all       0.025603  0.010359  3.881892e-03  4.428338e-07  0.024348  0.090197   \n",
       "\n",
       "             CIDEr     SPICE  \n",
       "Variant1  0.111948  0.040280  \n",
       "Variant2  0.050843  0.046499  \n",
       "variant3  0.127896  0.018054  \n",
       "all       0.091102  0.036919  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with 'v1', 'v2', 'v3', 'all' as the index\n",
    "index = ['Variant1', 'Variant2', 'variant3', 'all']\n",
    "random_data_df = pd.DataFrame(fine_by_random_data, index=index)\n",
    "random_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIDEr  SPICE\n",
       "Variant1  0.060  0.006\n",
       "Variant2  0.033  0.027\n",
       "variant3  0.089  0.039\n",
       "all       0.065  0.025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = base_df[['CIDEr', 'SPICE']]\n",
    "cadee_data_df = cadee_data_df[['CIDEr', 'SPICE']]\n",
    "random_data_df = random_data_df[['CIDEr', 'SPICE']]\n",
    "\n",
    "# round to 3 decimal places in python pandas\n",
    "base_df = base_df.round(3)\n",
    "cadee_data_df = cadee_data_df.round(3)\n",
    "random_data_df = random_data_df.round(3)\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {'Base': base_df, 'Random': random_data_df, 'CADEE': cadee_data_df}\n",
    "\n",
    "# Create a multi-index DataFrame by concatenating the dataframes along columns (axis=1)\n",
    "all_df = pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Base</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Random</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CADEE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Base        Random         CADEE       \n",
       "          CIDEr  SPICE  CIDEr  SPICE  CIDEr  SPICE\n",
       "Variant1  0.060  0.006  0.112  0.040  0.119  0.056\n",
       "Variant2  0.033  0.027  0.051  0.046  0.122  0.056\n",
       "variant3  0.089  0.039  0.128  0.018  0.237  0.096\n",
       "all       0.065  0.025  0.091  0.037  0.169  0.067"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv with index\n",
    "# format the output of pandas dataframe to csv to keep the zero in the end of the number\n",
    "all_df.to_csv('ped_all_df.csv', index=True, float_format='%.3f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lavistest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
