{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xtest/projects/lavis_test/LAVIS\n",
      "app\t\t    evaluate.py  pyproject.toml\t\t    setup.py\n",
      "assets\t\t    examples\t README.md\t\t    tests\n",
      "CODE_OF_CONDUCT.md  lavis\t requirements.txt\t    train.py\n",
      "CODEOWNERS\t    LICENSE.txt  run_scripts\n",
      "dataset_card\t    MANIFEST.in  salesforce_lavis.egg-info\n",
      "docs\t\t    projects\t SECURITY.md\n"
     ]
    }
   ],
   "source": [
    "%cd LAVIS\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 12:58:46,837 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 12:58:46,838 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 12:58:46,838 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 12:58:46,838 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 12:58:46,838 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 12:58:46,838 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 12:58:46,838 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 12:58:46,839 [INFO] Building datasets...\n",
      "2023-09-25 12:58:51,648 [INFO] Missing keys []\n",
      "2023-09-25 12:58:51,649 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-25 12:58:51,663 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 12:58:51,663 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 12:58:51,663 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 12:58:51,663 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 12:58:51,664 [INFO] Empty train splits.\n",
      "2023-09-25 12:58:51,664 [INFO] Empty train splits.\n",
      "2023-09-25 12:58:51,664 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.3410  data: 0.8413  max mem: 2048\n",
      "Evaluation Total time: 0:00:03 (3.3421 s / it)\n",
      "2023-09-25 12:58:55,468 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925125/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 383 tokens at 3752.33 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 1628.51 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 143, 'reflen': 369, 'guess': [143, 128, 113, 98], 'correct': [11, 1, 0, 0]}\n",
      "ratio: 0.38753387533770317\n",
      "Bleu_1: 0.016\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.011\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.063\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.066\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.673 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 13.48 s\n",
      "SPICE: 0.006\n",
      "Bleu_1: 0.016\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.011\n",
      "ROUGE_L: 0.063\n",
      "CIDEr: 0.066\n",
      "SPICE: 0.006\n"
     ]
    }
   ],
   "source": [
    "# t1 test\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic2\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 0, world 2): env://\n",
      "| distributed init (rank 1, world 2): env://\n",
      "2023-09-25 13:01:51,874 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:01:51,875 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:01:51,875 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:01:51,875 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:01:51,876 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:01:51,876 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:01:51,876 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:01:51,877 [INFO] Building datasets...\n",
      "2023-09-25 13:01:57,580 [INFO] Missing keys []\n",
      "2023-09-25 13:01:57,581 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-25 13:01:57,590 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:01:57,590 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:01:57,590 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:01:57,590 [INFO] Loaded 16 records for test split from the dataset.\n",
      "2023-09-25 13:01:57,590 [INFO] Empty train splits.\n",
      "2023-09-25 13:01:57,590 [INFO] Empty train splits.\n",
      "2023-09-25 13:01:57,590 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6440  data: 1.1091  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.6452 s / it)\n",
      "2023-09-25 13:02:01,661 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925130/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 614 tokens at 5923.44 tokens per second.\n",
      "PTBTokenizer tokenized 176 tokens at 1752.37 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 161, 'reflen': 599, 'guess': [161, 145, 129, 113], 'correct': [29, 2, 0, 0]}\n",
      "ratio: 0.2687813021698351\n",
      "Bleu_1: 0.012\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.015\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.051\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.021\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.984 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.47 s\n",
      "SPICE: 0.020\n",
      "Bleu_1: 0.012\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.015\n",
      "ROUGE_L: 0.051\n",
      "CIDEr: 0.021\n",
      "SPICE: 0.020\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic3\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:03:24,994 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:03:24,995 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:03:24,995 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:03:24,996 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:03:24,996 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:03:24,996 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:03:24,996 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:03:24,997 [INFO] Building datasets...\n",
      "2023-09-25 13:03:29,753 [INFO] Missing keys []\n",
      "2023-09-25 13:03:29,754 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-25 13:03:29,769 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:03:29,769 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:03:29,769 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:03:29,769 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 13:03:29,769 [INFO] Empty train splits.\n",
      "2023-09-25 13:03:29,769 [INFO] Empty train splits.\n",
      "2023-09-25 13:03:29,769 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.2397  data: 0.9841  max mem: 2045\n",
      "Evaluation Total time: 0:00:03 (3.2408 s / it)\n",
      "2023-09-25 13:03:33,285 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925130/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 406 tokens at 3916.62 tokens per second.\n",
      "PTBTokenizer tokenized 152 tokens at 1541.29 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 137, 'reflen': 392, 'guess': [137, 122, 107, 92], 'correct': [22, 2, 0, 0]}\n",
      "ratio: 0.3494897959174758\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.020\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.050\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.020\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [8.548 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.26 s\n",
      "SPICE: 0.013\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.020\n",
      "ROUGE_L: 0.050\n",
      "CIDEr: 0.020\n",
      "SPICE: 0.013\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 12:51:41,602 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 12:51:41,603 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 12:51:41,603 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 12:51:41,603 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 12:51:41,604 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 12:51:41,604 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 12:51:41,604 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 12:51:41,605 [INFO] Building datasets...\n",
      "2023-09-25 12:51:46,535 [INFO] Missing keys []\n",
      "2023-09-25 12:51:46,535 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\n",
      "2023-09-25 12:51:46,549 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 12:51:46,549 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 12:51:46,549 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 12:51:46,549 [INFO] Loaded 41 records for test split from the dataset.\n",
      "2023-09-25 12:51:46,549 [INFO] Empty train splits.\n",
      "2023-09-25 12:51:46,549 [INFO] Empty train splits.\n",
      "2023-09-25 12:51:46,549 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.3207  data: 2.0488  max mem: 2572\n",
      "Evaluation Total time: 0:00:05 (5.3219 s / it)\n",
      "2023-09-25 12:51:52,147 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925125/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1258 tokens at 11803.21 tokens per second.\n",
      "PTBTokenizer tokenized 436 tokens at 4394.61 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 395, 'reflen': 1218, 'guess': [395, 354, 313, 272], 'correct': [58, 5, 0, 0]}\n",
      "ratio: 0.324302134646696\n",
      "Bleu_1: 0.018\n",
      "Bleu_2: 0.006\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.016\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.058\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.039\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.367 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.592 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.28 s\n",
      "SPICE: 0.014\n",
      "Bleu_1: 0.018\n",
      "Bleu_2: 0.006\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.016\n",
      "ROUGE_L: 0.058\n",
      "CIDEr: 0.039\n",
      "SPICE: 0.014\n"
     ]
    }
   ],
   "source": [
    "# base on three topics\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train on cadee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 12:38:47,764 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 12:38:47,766 [INFO] {\n",
      "    \"amp\": false,\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": false,\n",
      "    \"gpu\": 0,\n",
      "    \"init_lr\": 1e-05,\n",
      "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
      "    \"max_epoch\": 10,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"min_lr\": 0,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"resume_ckpt_path\": null,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"train_splits\": [\n",
      "        \"train\"\n",
      "    ],\n",
      "    \"valid_splits\": [\n",
      "        \"val\"\n",
      "    ],\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 12:38:47,766 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 12:38:47,766 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 12:38:47,766 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_caption\",\n",
      "            \"prompt\": \"a picture of \"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_image_train\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 12:38:47,766 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 12:38:47,766 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": false,\n",
      "    \"load_pretrained\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 12:38:47,767 [INFO] Building datasets...\n",
      "reshape position embedding from 196 to 576\n",
      "2023-09-25 12:38:54,490 [INFO] Missing keys []\n",
      "2023-09-25 12:38:54,491 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n",
      "2023-09-25 12:38:54,504 [INFO] Start training\n",
      "2023-09-25 12:38:54,615 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 12:38:54,615 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 12:38:54,615 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 12:38:54,615 [INFO] Loaded 41 records for test split from the dataset.\n",
      "2023-09-25 12:38:54,617 [INFO] number of trainable parameters: 223971644\n",
      "2023-09-25 12:38:54,618 [INFO] Start training epoch 0, 2 iters per inner epoch.\n",
      "Train: data epoch: [0]  [0/2]  eta: 0:00:13  lr: 0.000010  loss: 7.1905  loss_lm: 7.1905 (7.1905)  time: 6.6662  data: 0.0000  max mem: 21859\n",
      "2023-09-25 12:39:01,525 [INFO] Reducer buckets have been rebuilt in this iteration.\n",
      "Train: data epoch: [0]  [1/2]  eta: 0:00:04  lr: 0.000010  loss: 6.9498  loss_lm: 6.9498 (7.0702)  time: 4.0433  data: 0.0000  max mem: 23532\n",
      "Train: data epoch: [0] Total time: 0:00:08 (4.0442 s / it)\n",
      "2023-09-25 12:39:02,710 [INFO] Averaged stats: lr: 0.0000  loss: 7.2242  loss_lm: 7.2242\n",
      "2023-09-25 12:39:02,713 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6396  data: 2.1203  max mem: 23532\n",
      "Evaluation Total time: 0:00:03 (3.6409 s / it)\n",
      "2023-09-25 12:39:06,364 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch0.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9691.16 tokens per second.\n",
      "PTBTokenizer tokenized 290 tokens at 2838.89 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 245, 'reflen': 1002, 'guess': [245, 205, 165, 125], 'correct': [51, 9, 2, 0]}\n",
      "ratio: 0.24451097804366814\n",
      "Bleu_1: 0.009\n",
      "Bleu_2: 0.004\n",
      "Bleu_3: 0.002\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.023\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.070\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.078\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [8.759 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.489 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 17.16 s\n",
      "SPICE: 0.017\n",
      "Bleu_1: 0.009\n",
      "Bleu_2: 0.004\n",
      "Bleu_3: 0.002\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.023\n",
      "ROUGE_L: 0.070\n",
      "CIDEr: 0.078\n",
      "SPICE: 0.017\n",
      "2023-09-25 12:39:33,244 [INFO] Saving checkpoint at epoch 0 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "2023-09-25 12:39:36,340 [INFO] Start training\n",
      "2023-09-25 12:39:36,348 [INFO] Start training epoch 1, 2 iters per inner epoch.\n",
      "Train: data epoch: [1]  [0/2]  eta: 0:00:11  lr: 0.000010  loss: 6.8544  loss_lm: 6.8544 (6.8544)  time: 5.9386  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1]  [1/2]  eta: 0:00:03  lr: 0.000010  loss: 6.8301  loss_lm: 6.8301 (6.8423)  time: 3.6689  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1] Total time: 0:00:07 (3.6705 s / it)\n",
      "2023-09-25 12:39:43,693 [INFO] Averaged stats: lr: 0.0000  loss: 6.7017  loss_lm: 6.7017\n",
      "2023-09-25 12:39:43,695 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.5827  data: 2.0379  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.5842 s / it)\n",
      "2023-09-25 12:39:47,290 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch1.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9735.13 tokens per second.\n",
      "PTBTokenizer tokenized 334 tokens at 3264.24 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 283, 'reflen': 1002, 'guess': [283, 243, 203, 164], 'correct': [64, 11, 1, 0]}\n",
      "ratio: 0.2824351297402371\n",
      "Bleu_1: 0.018\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.077\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.050\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.931 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.513 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.37 s\n",
      "SPICE: 0.016\n",
      "Bleu_1: 0.018\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.077\n",
      "CIDEr: 0.050\n",
      "SPICE: 0.016\n",
      "2023-09-25 12:40:11,210 [INFO] Start training\n",
      "2023-09-25 12:40:11,231 [INFO] Start training epoch 2, 2 iters per inner epoch.\n",
      "Train: data epoch: [2]  [0/2]  eta: 0:00:10  lr: 0.000009  loss: 6.5183  loss_lm: 6.5183 (6.5183)  time: 5.2075  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [2]  [1/2]  eta: 0:00:03  lr: 0.000009  loss: 6.6830  loss_lm: 6.5183 (6.6006)  time: 3.2584  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [2] Total time: 0:00:06 (3.2602 s / it)\n",
      "2023-09-25 12:40:17,754 [INFO] Averaged stats: lr: 0.0000  loss: 6.4301  loss_lm: 6.4301\n",
      "2023-09-25 12:40:17,756 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6146  data: 2.0699  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6162 s / it)\n",
      "2023-09-25 12:40:21,383 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch2.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9627.74 tokens per second.\n",
      "PTBTokenizer tokenized 341 tokens at 3322.55 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 290, 'reflen': 1002, 'guess': [290, 250, 210, 170], 'correct': [64, 8, 0, 0]}\n",
      "ratio: 0.2894211576843419\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.088\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.095\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.247 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.594 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.13 s\n",
      "SPICE: 0.030\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.088\n",
      "CIDEr: 0.095\n",
      "SPICE: 0.030\n",
      "2023-09-25 12:40:44,937 [INFO] Saving checkpoint at epoch 2 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "2023-09-25 12:40:55,905 [INFO] Start training\n",
      "2023-09-25 12:40:55,925 [INFO] Start training epoch 3, 2 iters per inner epoch.\n",
      "Train: data epoch: [3]  [0/2]  eta: 0:00:14  lr: 0.000008  loss: 6.3528  loss_lm: 6.3528 (6.3528)  time: 7.0255  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [3]  [1/2]  eta: 0:00:04  lr: 0.000008  loss: 6.2463  loss_lm: 6.2463 (6.2996)  time: 4.1478  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [3] Total time: 0:00:08 (4.1488 s / it)\n",
      "2023-09-25 12:41:04,227 [INFO] Averaged stats: lr: 0.0000  loss: 6.3163  loss_lm: 6.3163\n",
      "2023-09-25 12:41:04,229 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6428  data: 2.0760  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6444 s / it)\n",
      "2023-09-25 12:41:07,884 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch3.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9708.48 tokens per second.\n",
      "PTBTokenizer tokenized 352 tokens at 3396.17 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 301, 'reflen': 1002, 'guess': [301, 261, 221, 181], 'correct': [67, 7, 1, 0]}\n",
      "ratio: 0.30039920159650657\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.083\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.083\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.806 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.668 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.72 s\n",
      "SPICE: 0.036\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.008\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.083\n",
      "CIDEr: 0.083\n",
      "SPICE: 0.036\n",
      "2023-09-25 12:41:32,064 [INFO] Start training\n",
      "2023-09-25 12:41:32,085 [INFO] Start training epoch 4, 2 iters per inner epoch.\n",
      "Train: data epoch: [4]  [0/2]  eta: 0:00:10  lr: 0.000007  loss: 6.2610  loss_lm: 6.2610 (6.2610)  time: 5.4523  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [4]  [1/2]  eta: 0:00:03  lr: 0.000007  loss: 6.3954  loss_lm: 6.2610 (6.3282)  time: 3.3530  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [4] Total time: 0:00:06 (3.3559 s / it)\n",
      "2023-09-25 12:41:38,801 [INFO] Averaged stats: lr: 0.0000  loss: 6.3117  loss_lm: 6.3117\n",
      "2023-09-25 12:41:38,803 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6641  data: 2.1158  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6658 s / it)\n",
      "2023-09-25 12:41:42,480 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch4.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9704.36 tokens per second.\n",
      "PTBTokenizer tokenized 368 tokens at 3563.35 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 314, 'reflen': 1002, 'guess': [314, 274, 234, 194], 'correct': [65, 11, 3, 0]}\n",
      "ratio: 0.31337325349270123\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.031\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.090\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.103\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.888 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.440 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.67 s\n",
      "SPICE: 0.033\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.031\n",
      "ROUGE_L: 0.090\n",
      "CIDEr: 0.103\n",
      "SPICE: 0.033\n",
      "2023-09-25 12:42:05,409 [INFO] Saving checkpoint at epoch 4 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "2023-09-25 12:42:16,142 [INFO] Start training\n",
      "2023-09-25 12:42:16,162 [INFO] Start training epoch 5, 2 iters per inner epoch.\n",
      "Train: data epoch: [5]  [0/2]  eta: 0:00:13  lr: 0.000005  loss: 6.1632  loss_lm: 6.1632 (6.1632)  time: 6.5774  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [5]  [1/2]  eta: 0:00:03  lr: 0.000005  loss: 6.3755  loss_lm: 6.1632 (6.2693)  time: 3.9208  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [5] Total time: 0:00:07 (3.9236 s / it)\n",
      "2023-09-25 12:42:24,013 [INFO] Averaged stats: lr: 0.0000  loss: 6.1987  loss_lm: 6.1987\n",
      "2023-09-25 12:42:24,015 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6015  data: 2.0313  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6030 s / it)\n",
      "2023-09-25 12:42:27,629 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch5.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9653.61 tokens per second.\n",
      "PTBTokenizer tokenized 368 tokens at 3609.03 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 313, 'reflen': 1002, 'guess': [313, 273, 233, 193], 'correct': [64, 11, 3, 0]}\n",
      "ratio: 0.31237524950068624\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.031\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.090\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.103\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.918 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.312 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.48 s\n",
      "SPICE: 0.032\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.031\n",
      "ROUGE_L: 0.090\n",
      "CIDEr: 0.103\n",
      "SPICE: 0.032\n",
      "2023-09-25 12:42:52,290 [INFO] Saving checkpoint at epoch 5 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "2023-09-25 12:43:03,200 [INFO] Start training\n",
      "2023-09-25 12:43:03,219 [INFO] Start training epoch 6, 2 iters per inner epoch.\n",
      "Train: data epoch: [6]  [0/2]  eta: 0:00:11  lr: 0.000003  loss: 6.0181  loss_lm: 6.0181 (6.0181)  time: 5.9144  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [6]  [1/2]  eta: 0:00:03  lr: 0.000003  loss: 5.9579  loss_lm: 5.9579 (5.9880)  time: 3.6099  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [6] Total time: 0:00:07 (3.6109 s / it)\n",
      "2023-09-25 12:43:10,445 [INFO] Averaged stats: lr: 0.0000  loss: 6.1432  loss_lm: 6.1432\n",
      "2023-09-25 12:43:10,448 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6200  data: 2.0647  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6215 s / it)\n",
      "2023-09-25 12:43:14,080 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch6.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9664.18 tokens per second.\n",
      "PTBTokenizer tokenized 364 tokens at 3560.26 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 312, 'reflen': 1002, 'guess': [312, 272, 232, 192], 'correct': [72, 11, 3, 0]}\n",
      "ratio: 0.3113772455086713\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.033\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.099\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.113\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.99 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.417 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.19 s\n",
      "SPICE: 0.039\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.033\n",
      "ROUGE_L: 0.099\n",
      "CIDEr: 0.113\n",
      "SPICE: 0.039\n",
      "2023-09-25 12:43:40,940 [INFO] Saving checkpoint at epoch 6 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "2023-09-25 12:43:52,328 [INFO] Start training\n",
      "2023-09-25 12:43:52,347 [INFO] Start training epoch 7, 2 iters per inner epoch.\n",
      "Train: data epoch: [7]  [0/2]  eta: 0:00:11  lr: 0.000002  loss: 5.9834  loss_lm: 5.9834 (5.9834)  time: 5.7591  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [7]  [1/2]  eta: 0:00:03  lr: 0.000002  loss: 6.3658  loss_lm: 5.9834 (6.1746)  time: 3.5254  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [7] Total time: 0:00:07 (3.5269 s / it)\n",
      "2023-09-25 12:43:59,405 [INFO] Averaged stats: lr: 0.0000  loss: 6.1258  loss_lm: 6.1258\n",
      "2023-09-25 12:43:59,408 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6911  data: 2.1297  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6927 s / it)\n",
      "2023-09-25 12:44:03,111 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch7.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9631.93 tokens per second.\n",
      "PTBTokenizer tokenized 375 tokens at 3635.61 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 326, 'reflen': 1002, 'guess': [326, 286, 246, 206], 'correct': [72, 11, 3, 0]}\n",
      "ratio: 0.3253493013968809\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.033\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.097\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.109\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.45 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.318 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.95 s\n",
      "SPICE: 0.038\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.033\n",
      "ROUGE_L: 0.097\n",
      "CIDEr: 0.109\n",
      "SPICE: 0.038\n",
      "2023-09-25 12:44:26,751 [INFO] Start training\n",
      "2023-09-25 12:44:26,773 [INFO] Start training epoch 8, 2 iters per inner epoch.\n",
      "Train: data epoch: [8]  [0/2]  eta: 0:00:11  lr: 0.000001  loss: 5.8889  loss_lm: 5.8889 (5.8889)  time: 5.5721  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [8]  [1/2]  eta: 0:00:03  lr: 0.000001  loss: 6.3536  loss_lm: 5.8889 (6.1212)  time: 3.4407  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [8] Total time: 0:00:06 (3.4418 s / it)\n",
      "2023-09-25 12:44:33,661 [INFO] Averaged stats: lr: 0.0000  loss: 6.1120  loss_lm: 6.1120\n",
      "2023-09-25 12:44:33,663 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6055  data: 2.0460  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6071 s / it)\n",
      "2023-09-25 12:44:37,280 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch8.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9677.01 tokens per second.\n",
      "PTBTokenizer tokenized 361 tokens at 3545.54 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 314, 'reflen': 1002, 'guess': [314, 274, 234, 194], 'correct': [70, 11, 3, 0]}\n",
      "ratio: 0.31337325349270123\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.032\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.096\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.109\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.190 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.40 s\n",
      "SPICE: 0.039\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.011\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.032\n",
      "ROUGE_L: 0.096\n",
      "CIDEr: 0.109\n",
      "SPICE: 0.039\n",
      "2023-09-25 12:45:02,145 [INFO] Start training\n",
      "2023-09-25 12:45:02,166 [INFO] Start training epoch 9, 2 iters per inner epoch.\n",
      "Train: data epoch: [9]  [0/2]  eta: 0:00:11  lr: 0.000000  loss: 6.3835  loss_lm: 6.3835 (6.3835)  time: 5.7581  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [9]  [1/2]  eta: 0:00:03  lr: 0.000000  loss: 5.8672  loss_lm: 5.8672 (6.1254)  time: 3.5268  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [9] Total time: 0:00:07 (3.5283 s / it)\n",
      "2023-09-25 12:45:09,227 [INFO] Averaged stats: lr: 0.0000  loss: 6.0579  loss_lm: 6.0579\n",
      "2023-09-25 12:45:09,230 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.6527  data: 2.1102  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.6546 s / it)\n",
      "2023-09-25 12:45:12,895 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/val_epoch9.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1041 tokens at 9763.31 tokens per second.\n",
      "PTBTokenizer tokenized 368 tokens at 3596.40 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 321, 'reflen': 1002, 'guess': [321, 281, 241, 201], 'correct': [74, 12, 3, 0]}\n",
      "ratio: 0.32035928143680603\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.033\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.099\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.109\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.939 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"boeings blended wing body concept boeings advanced vehicle concept centers around the familiar blended wing body design like the x48 what makes this design different is the placement of its pratt amp whitney geared turbofan engines on the top of the planes back end flanked by two vertical tails to shield people on the ground from engine noise the design also uses other technologies to reduce noise and drag and longspan wings to improve fuel efficiency this design is among those presented to nasa at the end of 2011 by companies that conducted nasafunded studies into aircraft that could enter service in 2025\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.148 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.99 s\n",
      "SPICE: 0.037\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.033\n",
      "ROUGE_L: 0.099\n",
      "CIDEr: 0.109\n",
      "SPICE: 0.037\n",
      "2023-09-25 12:45:40,932 [INFO] Loading checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/checkpoint_best.pth.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.9229  data: 2.3072  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.9245 s / it)\n",
      "2023-09-25 12:45:46,837 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925123/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1258 tokens at 11856.41 tokens per second.\n",
      "PTBTokenizer tokenized 389 tokens at 3767.30 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 337, 'reflen': 1218, 'guess': [337, 296, 255, 214], 'correct': [52, 9, 3, 0]}\n",
      "ratio: 0.27668308702768746\n",
      "Bleu_1: 0.011\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.022\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.057\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.057\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.744 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.852 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 16.04 s\n",
      "SPICE: 0.019\n",
      "Bleu_1: 0.011\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.022\n",
      "ROUGE_L: 0.057\n",
      "CIDEr: 0.057\n",
      "SPICE: 0.019\n",
      "2023-09-25 12:46:11,430 [INFO] Training time 0:07:16\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=2 train.py --cfg-path lavis/projects/blip/train/caption_coco_ft.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:06:05,378 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:06:05,379 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:06:05,379 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:06:05,380 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:06:05,380 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:06:05,380 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:06:05,380 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:06:05,381 [INFO] Building datasets...\n",
      "2023-09-25 13:06:11,713 [INFO] Missing keys []\n",
      "2023-09-25 13:06:11,714 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\n",
      "2023-09-25 13:06:11,726 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:06:11,726 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:06:11,726 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:06:11,726 [INFO] Loaded 41 records for test split from the dataset.\n",
      "2023-09-25 13:06:11,726 [INFO] Empty train splits.\n",
      "2023-09-25 13:06:11,726 [INFO] Empty train splits.\n",
      "2023-09-25 13:06:11,726 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.2945  data: 2.0338  max mem: 2572\n",
      "Evaluation Total time: 0:00:05 (5.2957 s / it)\n",
      "2023-09-25 13:06:17,156 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925130/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1258 tokens at 11669.17 tokens per second.\n",
      "PTBTokenizer tokenized 389 tokens at 3779.60 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 337, 'reflen': 1218, 'guess': [337, 296, 255, 214], 'correct': [52, 9, 3, 0]}\n",
      "ratio: 0.27668308702768746\n",
      "Bleu_1: 0.011\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.022\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.057\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.057\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.333 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 13.56 s\n",
      "SPICE: 0.019\n",
      "Bleu_1: 0.011\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.022\n",
      "ROUGE_L: 0.057\n",
      "CIDEr: 0.057\n",
      "SPICE: 0.019\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:09:26,901 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:09:26,902 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:09:26,902 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:09:26,902 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:09:26,903 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:09:26,903 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:09:26,903 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:09:26,904 [INFO] Building datasets...\n",
      "2023-09-25 13:09:31,911 [INFO] Missing keys []\n",
      "2023-09-25 13:09:31,911 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\n",
      "2023-09-25 13:09:31,924 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:09:31,924 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:09:31,925 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:09:31,925 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 13:09:31,925 [INFO] Empty train splits.\n",
      "2023-09-25 13:09:31,925 [INFO] Empty train splits.\n",
      "2023-09-25 13:09:31,925 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:02    time: 2.9290  data: 0.6892  max mem: 2053\n",
      "Evaluation Total time: 0:00:02 (2.9303 s / it)\n",
      "2023-09-25 13:09:35,575 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925130/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 383 tokens at 3764.98 tokens per second.\n",
      "PTBTokenizer tokenized 147 tokens at 1522.17 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 129, 'reflen': 369, 'guess': [129, 114, 99, 84], 'correct': [8, 1, 0, 0]}\n",
      "ratio: 0.34959349593401196\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.004\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.020\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.068\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.096\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.648 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.63 s\n",
      "SPICE: 0.007\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.004\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.020\n",
      "ROUGE_L: 0.068\n",
      "CIDEr: 0.096\n",
      "SPICE: 0.007\n"
     ]
    }
   ],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:11:06,466 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:11:06,467 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:11:06,467 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:11:06,467 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:11:06,468 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:11:06,468 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:11:06,468 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:11:06,469 [INFO] Building datasets...\n",
      "2023-09-25 13:11:11,585 [INFO] Missing keys []\n",
      "2023-09-25 13:11:11,585 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\n",
      "2023-09-25 13:11:11,604 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:11:11,604 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:11:11,604 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:11:11,604 [INFO] Loaded 16 records for test split from the dataset.\n",
      "2023-09-25 13:11:11,604 [INFO] Empty train splits.\n",
      "2023-09-25 13:11:11,604 [INFO] Empty train splits.\n",
      "2023-09-25 13:11:11,604 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.5727  data: 1.1787  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.5739 s / it)\n",
      "2023-09-25 13:11:15,439 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925131/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 614 tokens at 5795.17 tokens per second.\n",
      "PTBTokenizer tokenized 174 tokens at 1768.43 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 151, 'reflen': 599, 'guess': [151, 135, 119, 103], 'correct': [27, 3, 1, 0]}\n",
      "ratio: 0.2520868113518329\n",
      "Bleu_1: 0.009\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.002\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.017\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.047\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.004\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.300 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.08 s\n",
      "SPICE: 0.006\n",
      "Bleu_1: 0.009\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.002\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.017\n",
      "ROUGE_L: 0.047\n",
      "CIDEr: 0.004\n",
      "SPICE: 0.006\n"
     ]
    }
   ],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:12:33,333 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:12:33,334 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:12:33,334 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:12:33,334 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:12:33,335 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:12:33,335 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:12:33,335 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:12:33,336 [INFO] Building datasets...\n",
      "2023-09-25 13:12:37,998 [INFO] Missing keys []\n",
      "2023-09-25 13:12:37,998 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_finetune/checkpoint_best.pth\n",
      "2023-09-25 13:12:38,007 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:12:38,007 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:12:38,007 [INFO] Loaded 40 records for val split from the dataset.\n",
      "2023-09-25 13:12:38,007 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 13:12:38,007 [INFO] Empty train splits.\n",
      "2023-09-25 13:12:38,008 [INFO] Empty train splits.\n",
      "2023-09-25 13:12:38,008 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.4363  data: 1.1260  max mem: 2046\n",
      "Evaluation Total time: 0:00:03 (3.4374 s / it)\n",
      "2023-09-25 13:12:41,817 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925131/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 406 tokens at 4037.22 tokens per second.\n",
      "PTBTokenizer tokenized 119 tokens at 1217.40 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 103, 'reflen': 392, 'guess': [103, 88, 73, 58], 'correct': [21, 5, 2, 0]}\n",
      "ratio: 0.262755102040146\n",
      "Bleu_1: 0.012\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.026\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.050\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.013\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [7.326 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 13.32 s\n",
      "SPICE: 0.039\n",
      "Bleu_1: 0.012\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.026\n",
      "ROUGE_L: 0.050\n",
      "CIDEr: 0.013\n",
      "SPICE: 0.039\n"
     ]
    }
   ],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train_av_r.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val_av_r.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt_av_r.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 13:46:24,342 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:46:24,343 [INFO] {\n",
      "    \"amp\": false,\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": false,\n",
      "    \"gpu\": 0,\n",
      "    \"init_lr\": 1e-05,\n",
      "    \"lr_sched\": \"linear_warmup_cosine_lr\",\n",
      "    \"max_epoch\": 10,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"min_lr\": 0,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"resume_ckpt_path\": null,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"train_splits\": [\n",
      "        \"train\"\n",
      "    ],\n",
      "    \"valid_splits\": [\n",
      "        \"val\"\n",
      "    ],\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:46:24,343 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:46:24,343 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:46:24,344 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_caption\",\n",
      "            \"prompt\": \"a picture of \"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"name\": \"blip_image_train\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:46:24,344 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:46:24,344 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP/blip_coco_caption_base.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": false,\n",
      "    \"load_pretrained\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:46:24,345 [INFO] Building datasets...\n",
      "reshape position embedding from 196 to 576\n",
      "2023-09-25 13:46:31,667 [INFO] Missing keys []\n",
      "2023-09-25 13:46:31,668 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n",
      "2023-09-25 13:46:31,682 [INFO] Start training\n",
      "2023-09-25 13:46:31,952 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:46:31,952 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:46:31,952 [INFO] Loaded 41 records for val split from the dataset.\n",
      "2023-09-25 13:46:31,952 [INFO] Loaded 41 records for test split from the dataset.\n",
      "2023-09-25 13:46:31,954 [INFO] number of trainable parameters: 223971644\n",
      "2023-09-25 13:46:31,955 [INFO] Start training epoch 0, 2 iters per inner epoch.\n",
      "Train: data epoch: [0]  [0/2]  eta: 0:00:12  lr: 0.000010  loss: 7.1604  loss_lm: 7.1604 (7.1604)  time: 6.3116  data: 0.0000  max mem: 21859\n",
      "2023-09-25 13:46:38,520 [INFO] Reducer buckets have been rebuilt in this iteration.\n",
      "Train: data epoch: [0]  [1/2]  eta: 0:00:03  lr: 0.000010  loss: 6.7015  loss_lm: 6.7015 (6.9310)  time: 3.8352  data: 0.0000  max mem: 23532\n",
      "Train: data epoch: [0] Total time: 0:00:07 (3.8362 s / it)\n",
      "2023-09-25 13:46:39,629 [INFO] Averaged stats: lr: 0.0000  loss: 6.8443  loss_lm: 6.8443\n",
      "2023-09-25 13:46:39,631 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0518  data: 2.4370  max mem: 23532\n",
      "Evaluation Total time: 0:00:04 (4.0531 s / it)\n",
      "2023-09-25 13:46:43,695 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch0.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10905.47 tokens per second.\n",
      "PTBTokenizer tokenized 334 tokens at 3302.78 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 279, 'reflen': 1151, 'guess': [279, 238, 197, 157], 'correct': [62, 5, 0, 0]}\n",
      "ratio: 0.2423979148564358\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.020\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.088\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.082\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [28.165 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.149 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 34.49 s\n",
      "SPICE: 0.035\n",
      "Bleu_1: 0.010\n",
      "Bleu_2: 0.003\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.020\n",
      "ROUGE_L: 0.088\n",
      "CIDEr: 0.082\n",
      "SPICE: 0.035\n",
      "2023-09-25 13:47:28,658 [INFO] Saving checkpoint at epoch 0 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/checkpoint_best.pth.\n",
      "2023-09-25 13:47:31,651 [INFO] Start training\n",
      "2023-09-25 13:47:31,659 [INFO] Start training epoch 1, 2 iters per inner epoch.\n",
      "Train: data epoch: [1]  [0/2]  eta: 0:00:13  lr: 0.000010  loss: 6.2318  loss_lm: 6.2318 (6.2318)  time: 6.5669  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1]  [1/2]  eta: 0:00:03  lr: 0.000010  loss: 6.2420  loss_lm: 6.2318 (6.2369)  time: 3.9303  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [1] Total time: 0:00:07 (3.9320 s / it)\n",
      "2023-09-25 13:47:39,525 [INFO] Averaged stats: lr: 0.0000  loss: 6.2060  loss_lm: 6.2060\n",
      "2023-09-25 13:47:39,528 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.9737  data: 2.3777  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.9753 s / it)\n",
      "2023-09-25 13:47:43,514 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch1.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10792.72 tokens per second.\n",
      "PTBTokenizer tokenized 383 tokens at 3743.25 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 321, 'reflen': 1151, 'guess': [321, 280, 239, 198], 'correct': [72, 5, 0, 0]}\n",
      "ratio: 0.2788879235445014\n",
      "Bleu_1: 0.017\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.022\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.092\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.056\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [25.664 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.449 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 32.36 s\n",
      "SPICE: 0.031\n",
      "Bleu_1: 0.017\n",
      "Bleu_2: 0.005\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.022\n",
      "ROUGE_L: 0.092\n",
      "CIDEr: 0.056\n",
      "SPICE: 0.031\n",
      "2023-09-25 13:48:24,396 [INFO] Start training\n",
      "2023-09-25 13:48:24,418 [INFO] Start training epoch 2, 2 iters per inner epoch.\n",
      "Train: data epoch: [2]  [0/2]  eta: 0:00:12  lr: 0.000009  loss: 5.9019  loss_lm: 5.9019 (5.9019)  time: 6.2029  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [2]  [1/2]  eta: 0:00:03  lr: 0.000009  loss: 6.0871  loss_lm: 5.9019 (5.9945)  time: 3.7497  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [2] Total time: 0:00:07 (3.7510 s / it)\n",
      "2023-09-25 13:48:31,923 [INFO] Averaged stats: lr: 0.0000  loss: 6.1331  loss_lm: 6.1331\n",
      "2023-09-25 13:48:31,925 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1258  data: 2.5130  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1274 s / it)\n",
      "2023-09-25 13:48:36,063 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch2.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10588.72 tokens per second.\n",
      "PTBTokenizer tokenized 415 tokens at 4008.32 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 359, 'reflen': 1151, 'guess': [359, 318, 277, 236], 'correct': [80, 6, 0, 0]}\n",
      "ratio: 0.3119026933098941\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.097\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.081\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [28.832 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.364 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 35.51 s\n",
      "SPICE: 0.041\n",
      "Bleu_1: 0.025\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.097\n",
      "CIDEr: 0.081\n",
      "SPICE: 0.041\n",
      "2023-09-25 13:49:20,307 [INFO] Start training\n",
      "2023-09-25 13:49:20,330 [INFO] Start training epoch 3, 2 iters per inner epoch.\n",
      "Train: data epoch: [3]  [0/2]  eta: 0:00:11  lr: 0.000008  loss: 5.9982  loss_lm: 5.9982 (5.9982)  time: 5.8853  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [3]  [1/2]  eta: 0:00:03  lr: 0.000008  loss: 6.0521  loss_lm: 5.9982 (6.0252)  time: 3.6072  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [3] Total time: 0:00:07 (3.6084 s / it)\n",
      "2023-09-25 13:49:27,551 [INFO] Averaged stats: lr: 0.0000  loss: 6.0002  loss_lm: 6.0002\n",
      "2023-09-25 13:49:27,554 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.7136  data: 2.0779  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.7151 s / it)\n",
      "2023-09-25 13:49:31,281 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch3.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10660.94 tokens per second.\n",
      "PTBTokenizer tokenized 408 tokens at 3932.52 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 355, 'reflen': 1151, 'guess': [355, 314, 273, 232], 'correct': [78, 13, 4, 2]}\n",
      "ratio: 0.3084274543872212\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.003\n",
      "computing METEOR score...\n",
      "METEOR: 0.028\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.084\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.071\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [26.57 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.860 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 33.36 s\n",
      "SPICE: 0.032\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.003\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.084\n",
      "CIDEr: 0.071\n",
      "SPICE: 0.032\n",
      "2023-09-25 13:50:14,851 [INFO] Start training\n",
      "2023-09-25 13:50:14,873 [INFO] Start training epoch 4, 2 iters per inner epoch.\n",
      "Train: data epoch: [4]  [0/2]  eta: 0:00:14  lr: 0.000007  loss: 5.8434  loss_lm: 5.8434 (5.8434)  time: 7.0666  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [4]  [1/2]  eta: 0:00:04  lr: 0.000007  loss: 5.9903  loss_lm: 5.8434 (5.9169)  time: 4.1818  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [4] Total time: 0:00:08 (4.1829 s / it)\n",
      "2023-09-25 13:50:23,242 [INFO] Averaged stats: lr: 0.0000  loss: 5.9151  loss_lm: 5.9151\n",
      "2023-09-25 13:50:23,245 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0414  data: 2.4219  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0429 s / it)\n",
      "2023-09-25 13:50:27,299 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch4.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10655.61 tokens per second.\n",
      "PTBTokenizer tokenized 400 tokens at 3883.43 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 351, 'reflen': 1151, 'guess': [351, 310, 269, 228], 'correct': [76, 14, 4, 1]}\n",
      "ratio: 0.30495221546454826\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.003\n",
      "computing METEOR score...\n",
      "METEOR: 0.028\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.087\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.071\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [26.108 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.440 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 33.16 s\n",
      "SPICE: 0.025\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.003\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.087\n",
      "CIDEr: 0.071\n",
      "SPICE: 0.025\n",
      "2023-09-25 13:51:09,152 [INFO] Start training\n",
      "2023-09-25 13:51:09,174 [INFO] Start training epoch 5, 2 iters per inner epoch.\n",
      "Train: data epoch: [5]  [0/2]  eta: 0:00:12  lr: 0.000005  loss: 6.1352  loss_lm: 6.1352 (6.1352)  time: 6.2719  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [5]  [1/2]  eta: 0:00:03  lr: 0.000005  loss: 5.6410  loss_lm: 5.6410 (5.8881)  time: 3.7773  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [5] Total time: 0:00:07 (3.7796 s / it)\n",
      "2023-09-25 13:51:16,737 [INFO] Averaged stats: lr: 0.0000  loss: 5.8945  loss_lm: 5.8945\n",
      "2023-09-25 13:51:16,739 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0416  data: 2.4319  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0431 s / it)\n",
      "2023-09-25 13:51:20,794 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch5.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10595.90 tokens per second.\n",
      "PTBTokenizer tokenized 396 tokens at 3819.36 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 347, 'reflen': 1151, 'guess': [347, 306, 265, 224], 'correct': [81, 12, 1, 0]}\n",
      "ratio: 0.30147697654187533\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.101\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.086\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [27.332 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.332 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 34.36 s\n",
      "SPICE: 0.034\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.101\n",
      "CIDEr: 0.086\n",
      "SPICE: 0.034\n",
      "2023-09-25 13:52:04,297 [INFO] Saving checkpoint at epoch 5 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/checkpoint_best.pth.\n",
      "2023-09-25 13:52:15,233 [INFO] Start training\n",
      "2023-09-25 13:52:15,253 [INFO] Start training epoch 6, 2 iters per inner epoch.\n",
      "Train: data epoch: [6]  [0/2]  eta: 0:00:13  lr: 0.000003  loss: 5.9437  loss_lm: 5.9437 (5.9437)  time: 6.9948  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [6]  [1/2]  eta: 0:00:04  lr: 0.000003  loss: 5.5260  loss_lm: 5.5260 (5.7348)  time: 4.1542  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [6] Total time: 0:00:08 (4.1565 s / it)\n",
      "2023-09-25 13:52:23,570 [INFO] Averaged stats: lr: 0.0000  loss: 5.7969  loss_lm: 5.7969\n",
      "2023-09-25 13:52:23,573 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0610  data: 2.4287  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0626 s / it)\n",
      "2023-09-25 13:52:27,647 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch6.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10729.53 tokens per second.\n",
      "PTBTokenizer tokenized 396 tokens at 3898.45 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 347, 'reflen': 1151, 'guess': [347, 306, 265, 224], 'correct': [82, 12, 1, 0]}\n",
      "ratio: 0.30147697654187533\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.030\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.105\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.090\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [26.860 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.252 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 33.33 s\n",
      "SPICE: 0.040\n",
      "Bleu_1: 0.023\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.030\n",
      "ROUGE_L: 0.105\n",
      "CIDEr: 0.090\n",
      "SPICE: 0.040\n",
      "2023-09-25 13:53:09,497 [INFO] Saving checkpoint at epoch 6 to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/checkpoint_best.pth.\n",
      "2023-09-25 13:53:20,232 [INFO] Start training\n",
      "2023-09-25 13:53:20,252 [INFO] Start training epoch 7, 2 iters per inner epoch.\n",
      "Train: data epoch: [7]  [0/2]  eta: 0:00:13  lr: 0.000002  loss: 5.7834  loss_lm: 5.7834 (5.7834)  time: 6.6028  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [7]  [1/2]  eta: 0:00:03  lr: 0.000002  loss: 5.7493  loss_lm: 5.7493 (5.7663)  time: 3.9642  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [7] Total time: 0:00:07 (3.9662 s / it)\n",
      "2023-09-25 13:53:28,189 [INFO] Averaged stats: lr: 0.0000  loss: 5.7834  loss_lm: 5.7834\n",
      "2023-09-25 13:53:28,191 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.1101  data: 2.4804  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.1118 s / it)\n",
      "2023-09-25 13:53:32,314 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch7.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10199.44 tokens per second.\n",
      "PTBTokenizer tokenized 400 tokens at 3916.47 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 352, 'reflen': 1151, 'guess': [352, 311, 270, 229], 'correct': [81, 12, 1, 0]}\n",
      "ratio: 0.3058210251952165\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.030\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.103\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.088\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [25.493 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.304 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 31.94 s\n",
      "SPICE: 0.034\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.030\n",
      "ROUGE_L: 0.103\n",
      "CIDEr: 0.088\n",
      "SPICE: 0.034\n",
      "2023-09-25 13:54:13,505 [INFO] Start training\n",
      "2023-09-25 13:54:13,527 [INFO] Start training epoch 8, 2 iters per inner epoch.\n",
      "Train: data epoch: [8]  [0/2]  eta: 0:00:12  lr: 0.000001  loss: 5.4824  loss_lm: 5.4824 (5.4824)  time: 6.2853  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [8]  [1/2]  eta: 0:00:03  lr: 0.000001  loss: 5.6578  loss_lm: 5.4824 (5.5701)  time: 3.8318  data: 0.0030  max mem: 23586\n",
      "Train: data epoch: [8] Total time: 0:00:07 (3.8328 s / it)\n",
      "2023-09-25 13:54:21,197 [INFO] Averaged stats: lr: 0.0000  loss: 5.6681  loss_lm: 5.6681\n",
      "2023-09-25 13:54:21,199 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.9883  data: 2.3717  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.9898 s / it)\n",
      "2023-09-25 13:54:25,200 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch8.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10542.58 tokens per second.\n",
      "PTBTokenizer tokenized 396 tokens at 3773.96 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 348, 'reflen': 1151, 'guess': [348, 307, 266, 225], 'correct': [78, 11, 1, 0]}\n",
      "ratio: 0.3023457862725436\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.096\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.077\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) [25.739 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.228 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 33.43 s\n",
      "SPICE: 0.032\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.096\n",
      "CIDEr: 0.077\n",
      "SPICE: 0.032\n",
      "2023-09-25 13:55:07,037 [INFO] Start training\n",
      "2023-09-25 13:55:07,059 [INFO] Start training epoch 9, 2 iters per inner epoch.\n",
      "Train: data epoch: [9]  [0/2]  eta: 0:00:11  lr: 0.000000  loss: 5.7543  loss_lm: 5.7543 (5.7543)  time: 5.9529  data: 0.0001  max mem: 23586\n",
      "Train: data epoch: [9]  [1/2]  eta: 0:00:03  lr: 0.000000  loss: 5.8246  loss_lm: 5.7543 (5.7894)  time: 3.6455  data: 0.0000  max mem: 23586\n",
      "Train: data epoch: [9] Total time: 0:00:07 (3.6467 s / it)\n",
      "2023-09-25 13:55:14,357 [INFO] Averaged stats: lr: 0.0000  loss: 5.8110  loss_lm: 5.8110\n",
      "2023-09-25 13:55:14,359 [INFO] Evaluating on val.\n",
      "Evaluation  [0/1]  eta: 0:00:04    time: 4.0606  data: 2.4393  max mem: 23586\n",
      "Evaluation Total time: 0:00:04 (4.0625 s / it)\n",
      "2023-09-25 13:55:18,433 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/val_epoch9.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_val_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1191 tokens at 10750.65 tokens per second.\n",
      "PTBTokenizer tokenized 394 tokens at 3832.98 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 346, 'reflen': 1151, 'guess': [346, 305, 264, 223], 'correct': [79, 11, 1, 0]}\n",
      "ratio: 0.3006081668112071\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.029\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.098\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.078\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Threads( StanfordCoreNLP ) [26.733 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"an aw performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower atlantic ocean jan 24 2009 aviation warfare systems operator 3rd class david bellows assigned to the nightdippers of helicopter antisubmarine squadron hs 5 performs maintenance on a 50caliber crewserved weapon aboard the aircraft carrier uss dwight d eisenhower cvn 69 during the carrier strike group 8 composite unit training exercise comptuex comptuex is a training exercise to test capabilities and ensure readiness before a deployment us navy photo by mass communication specialist 3rd class holly whitfillreleased\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"the mosquito bmk xvi ml963 of 571 squadron a royal air force de havilland mosquito bxvi serial ml963 in flight ml963 8kk king of no 571 squadron the picture having been taken on 30 september 1944 after the aircraft had completed repairs at hatfield ml963 was first issued to 109 squadron on 9 march 1944 going on to 692 squadron on the 24th of the same month and then on to 571 on 19 april 1944 it was damaged in action on 12 may 1944 but returned to the squadron on 23 october of that year ml963 completed 84 operations with the squadron 31 of them to berlin one of the others was a lowlevel sortie to skipbomb a 4000 lb bomb into the bitburg tunnel undertaken on new years day 1945 the crew were flt lt norman j griffiths amp flg off wr ball its final sortie came on 1011 april 1945 when it was abandoned following an engine fire the crew fo rd oliver and fs lm young raaf rejoined their squadron before the end of the month fo oliver reporting as early as 22 april 1945\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"critchell receives an smc coin from smc vice commander brigade general neil mccasland 28 march 20075 los angeles air force base to kick off womens history month the federal womens program committee sponsored a luncheon in the gordon conference center march 28 the guest speaker was mrs iris cummings critchell a very distinguished and honored aviator she is a member of the national association of flight instructors hall of fame and also honored by the faa with the wright brothers master pilot award a member of the wasp womens air force service pilots as well as an olympian during her speech women in aviation history their legacy and our challenge for the future mrs critchell highlighted her venerable career from the very beginning in aeronautics and flight 19391941 to include her work in the ferry command years 19421944 the allwoman transcontinental air race 19471977 and her experiences at both the university of southern california and harvey mudd college\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.167 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 33.67 s\n",
      "SPICE: 0.038\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.029\n",
      "ROUGE_L: 0.098\n",
      "CIDEr: 0.078\n",
      "SPICE: 0.038\n",
      "2023-09-25 13:56:01,667 [INFO] Loading checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/checkpoint_best.pth.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.9125  data: 2.3084  max mem: 23586\n",
      "Evaluation Total time: 0:00:03 (3.9141 s / it)\n",
      "2023-09-25 13:56:07,525 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925134/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1258 tokens at 11572.74 tokens per second.\n",
      "PTBTokenizer tokenized 436 tokens at 4172.55 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 385, 'reflen': 1218, 'guess': [385, 344, 303, 262], 'correct': [82, 17, 5, 0]}\n",
      "ratio: 0.316091954022729\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.066\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.054\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.122 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.67 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.93 s\n",
      "SPICE: 0.024\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.066\n",
      "CIDEr: 0.054\n",
      "SPICE: 0.024\n",
      "2023-09-25 13:56:30,811 [INFO] Training time 0:09:59\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.run --nproc_per_node=2 train.py --cfg-path lavis/projects/blip/train/caption_coco_ft.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 0, world 2): env://\n",
      "| distributed init (rank 1, world 2): env://\n",
      "2023-09-25 13:59:28,510 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 13:59:28,511 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 13:59:28,511 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 13:59:28,511 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 13:59:28,512 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 13:59:28,512 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 13:59:28,512 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 13:59:28,513 [INFO] Building datasets...\n",
      "2023-09-25 13:59:34,490 [INFO] Missing keys []\n",
      "2023-09-25 13:59:34,490 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\n",
      "2023-09-25 13:59:34,502 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 13:59:34,502 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 13:59:34,502 [INFO] Loaded 41 records for val split from the dataset.\n",
      "2023-09-25 13:59:34,502 [INFO] Loaded 41 records for test split from the dataset.\n",
      "2023-09-25 13:59:34,502 [INFO] Empty train splits.\n",
      "2023-09-25 13:59:34,502 [INFO] Empty train splits.\n",
      "2023-09-25 13:59:34,502 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:05    time: 5.4332  data: 2.1055  max mem: 2572\n",
      "Evaluation Total time: 0:00:05 (5.4351 s / it)\n",
      "2023-09-25 13:59:40,182 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925135/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 1258 tokens at 11619.16 tokens per second.\n",
      "PTBTokenizer tokenized 436 tokens at 4274.21 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 385, 'reflen': 1218, 'guess': [385, 344, 303, 262], 'correct': [82, 17, 5, 0]}\n",
      "ratio: 0.316091954022729\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.027\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.066\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.054\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.669 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.66 s\n",
      "SPICE: 0.024\n",
      "Bleu_1: 0.024\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.027\n",
      "ROUGE_L: 0.066\n",
      "CIDEr: 0.054\n",
      "SPICE: 0.024\n"
     ]
    }
   ],
   "source": [
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 14:03:19,401 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 14:03:19,403 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 14:03:19,403 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 14:03:19,403 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 14:03:19,403 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 14:03:19,403 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 14:03:19,404 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 14:03:19,404 [INFO] Building datasets...\n",
      "2023-09-25 14:03:24,389 [INFO] Missing keys []\n",
      "2023-09-25 14:03:24,389 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\n",
      "2023-09-25 14:03:24,408 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 14:03:24,408 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 14:03:24,408 [INFO] Loaded 41 records for val split from the dataset.\n",
      "2023-09-25 14:03:24,408 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 14:03:24,408 [INFO] Empty train splits.\n",
      "2023-09-25 14:03:24,408 [INFO] Empty train splits.\n",
      "2023-09-25 14:03:24,408 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.4044  data: 0.7678  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.4059 s / it)\n",
      "2023-09-25 14:03:28,747 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925140/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 383 tokens at 3827.93 tokens per second.\n",
      "PTBTokenizer tokenized 152 tokens at 1585.19 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 137, 'reflen': 369, 'guess': [137, 122, 107, 92], 'correct': [12, 2, 0, 0]}\n",
      "ratio: 0.3712737127361212\n",
      "Bleu_1: 0.016\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.018\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.057\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.071\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [6.657 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"royal air force of oman oneeleven model 485gd lands at riat 2008 royal air force of oman bac 111 model 485gd fin code 551 at the 2008 royal international air tattoo fairford gloucestershire england note that the apparent fin code of 001 is in arabic numerals and is 551 not 001 taken at riat fairford on the thursday before the weekend show days later both show days saturday and sunday were cancelled because of waterlogged car parks photographed by adrian pingstone in july 2008 and placed in the public domain\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 13.18 s\n",
      "SPICE: 0.016\n",
      "Bleu_1: 0.016\n",
      "Bleu_2: 0.007\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.018\n",
      "ROUGE_L: 0.057\n",
      "CIDEr: 0.071\n",
      "SPICE: 0.016\n"
     ]
    }
   ],
   "source": [
    "# t1 \n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t1.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 0, world 2): env://\n",
      "| distributed init (rank 1, world 2): env://\n",
      "2023-09-25 14:08:52,305 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 14:08:52,306 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 14:08:52,306 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 14:08:52,306 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 14:08:52,307 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 14:08:52,307 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 14:08:52,307 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 14:08:52,308 [INFO] Building datasets...\n",
      "2023-09-25 14:08:58,918 [INFO] Missing keys []\n",
      "2023-09-25 14:08:58,919 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\n",
      "2023-09-25 14:08:58,933 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 14:08:58,933 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 14:08:58,933 [INFO] Loaded 41 records for val split from the dataset.\n",
      "2023-09-25 14:08:58,933 [INFO] Loaded 16 records for test split from the dataset.\n",
      "2023-09-25 14:08:58,933 [INFO] Empty train splits.\n",
      "2023-09-25 14:08:58,933 [INFO] Empty train splits.\n",
      "2023-09-25 14:08:58,933 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.5930  data: 1.0602  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.5941 s / it)\n",
      "2023-09-25 14:09:02,915 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925140/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 614 tokens at 5860.34 tokens per second.\n",
      "PTBTokenizer tokenized 185 tokens at 1903.38 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 163, 'reflen': 599, 'guess': [163, 147, 131, 115], 'correct': [44, 9, 2, 0]}\n",
      "ratio: 0.27212020033343554\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.028\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.075\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.070\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.8 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.627 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"corsair fg1d goodyear built f4u1d in the royal new zealand air force markings corsair fg1d goodyear built equal to the f4u1d from which the rocket launcher stubs and pylons have been taken off wearing the colours of the royal new zealand air force rnzaf notice the clipped wing tips a characteristic of the carrierbased british corsairs lower deck height than us carriers bureau number160 88391 wartime registration160 nz5648 current civil registration160 gbxul owner160 the old flying machine company ofmc place160 strasbourg airport france\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 15.44 s\n",
      "SPICE: 0.027\n",
      "Bleu_1: 0.019\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.004\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.075\n",
      "CIDEr: 0.070\n",
      "SPICE: 0.027\n"
     ]
    }
   ],
   "source": [
    "# t2\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t2.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "| distributed init (rank 1, world 2): env://\n",
      "| distributed init (rank 0, world 2): env://\n",
      "2023-09-25 14:14:17,036 [INFO] \n",
      "=====  Running Parameters    =====\n",
      "2023-09-25 14:14:17,038 [INFO] {\n",
      "    \"batch_size_eval\": 64,\n",
      "    \"batch_size_train\": 32,\n",
      "    \"device\": \"cuda\",\n",
      "    \"dist_backend\": \"nccl\",\n",
      "    \"dist_url\": \"env://\",\n",
      "    \"distributed\": true,\n",
      "    \"evaluate\": true,\n",
      "    \"gpu\": 0,\n",
      "    \"max_len\": 20,\n",
      "    \"min_len\": 5,\n",
      "    \"num_beams\": 3,\n",
      "    \"num_workers\": 4,\n",
      "    \"output_dir\": \"output/BLIP/Caption_coco\",\n",
      "    \"rank\": 0,\n",
      "    \"seed\": 42,\n",
      "    \"task\": \"captioning\",\n",
      "    \"test_splits\": [\n",
      "        \"test\"\n",
      "    ],\n",
      "    \"world_size\": 2\n",
      "}\n",
      "2023-09-25 14:14:17,038 [INFO] \n",
      "======  Dataset Attributes  ======\n",
      "2023-09-25 14:14:17,038 [INFO] \n",
      "======== coco_caption =======\n",
      "2023-09-25 14:14:17,038 [INFO] {\n",
      "    \"build_info\": {\n",
      "        \"annotations\": {\n",
      "            \"test\": {\n",
      "                \"md5\": \"3ff34b0ef2db02d01c37399f6a2a6cd1\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_test.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json\"\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"md5\": \"aa31ac474cf6250ebb81d18348a07ed8\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_train.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json\"\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"md5\": \"b273847456ef5580e33713b1f7de52a0\",\n",
      "                \"storage\": \"coco/annotations/coco_karpathy_val.json\",\n",
      "                \"url\": \"https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json\"\n",
      "            }\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"storage\": \"coco/images/\"\n",
      "        }\n",
      "    },\n",
      "    \"data_type\": \"images\",\n",
      "    \"dataset_card\": \"dataset_card/coco_caption.md\",\n",
      "    \"text_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_caption\"\n",
      "        }\n",
      "    },\n",
      "    \"vis_processor\": {\n",
      "        \"eval\": {\n",
      "            \"name\": \"blip_image_eval\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "2023-09-25 14:14:17,038 [INFO] \n",
      "======  Model Attributes  ======\n",
      "2023-09-25 14:14:17,039 [INFO] {\n",
      "    \"arch\": \"blip_caption\",\n",
      "    \"finetuned\": \"/home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\",\n",
      "    \"image_size\": 384,\n",
      "    \"load_finetuned\": true,\n",
      "    \"med_config_path\": \"configs/models/med_config.json\",\n",
      "    \"model_type\": \"base_coco\",\n",
      "    \"pretrained\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\",\n",
      "    \"prompt\": \"a picture of \",\n",
      "    \"vit_ckpt_layer\": 0,\n",
      "    \"vit_grad_ckpt\": false,\n",
      "    \"vit_type\": \"base\"\n",
      "}\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_train.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_val.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
      "2023-09-25 14:14:17,040 [INFO] Building datasets...\n",
      "2023-09-25 14:14:23,125 [INFO] Missing keys []\n",
      "2023-09-25 14:14:23,126 [INFO] load checkpoint from /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/av_ran/checkpoint_best.pth\n",
      "2023-09-25 14:14:23,142 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).\n",
      "2023-09-25 14:14:23,143 [INFO] Loaded 184 records for train split from the dataset.\n",
      "2023-09-25 14:14:23,143 [INFO] Loaded 41 records for val split from the dataset.\n",
      "2023-09-25 14:14:23,143 [INFO] Loaded 15 records for test split from the dataset.\n",
      "2023-09-25 14:14:23,143 [INFO] Empty train splits.\n",
      "2023-09-25 14:14:23,143 [INFO] Empty train splits.\n",
      "2023-09-25 14:14:23,143 [INFO] Empty train splits.\n",
      "Evaluation  [0/1]  eta: 0:00:03    time: 3.5851  data: 1.0107  max mem: 2053\n",
      "Evaluation Total time: 0:00:03 (3.5867 s / it)\n",
      "2023-09-25 14:14:26,866 [WARNING] rank 0 starts merging results.\n",
      "result file saved to /home/xtest/projects/lavis_test/LAVIS/lavis/output/BLIP/Caption_coco/20230925141/result/test_epochbest.json\n",
      "Using downloaded and verified file: /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 406 tokens at 3947.47 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 1461.70 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 123, 'reflen': 392, 'guess': [123, 108, 93, 78], 'correct': [31, 7, 3, 0]}\n",
      "ratio: 0.3137755102032812\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.009\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.031\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.058\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.011\n",
      "computing SPICE score...\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [8.4 seconds]\n",
      "Error: Could not cache item to /home/xtest/miniconda3/envs/lavistest/lib/python3.8/site-packages/pycocoevalcap/spice/cache with key:\n",
      "\"one of the main features of the f4f4 were the stowingdesign folding wings a grumman patented design display of us navy grumman f4f4 wildcats showing that five with grummans stowings could occupy ther space of two without stowings like the f4f3 thereby increasing the stowage of aircraft and the striking force of carriers by about 150 percent grumman supplied all the us navys carrierbased fighters from 1935 until 1943 and throughout the war two out of three navy fighters and 98 out of 100 of the fleets torpedo bombers were either grummanmade or grummandesigned\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
      "SPICE evaluation took: 14.31 s\n",
      "SPICE: 0.033\n",
      "Bleu_1: 0.028\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.009\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.031\n",
      "ROUGE_L: 0.058\n",
      "CIDEr: 0.011\n",
      "SPICE: 0.033\n"
     ]
    }
   ],
   "source": [
    "# t3\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco_gt/coco_karpathy_test_gt.json\n",
    "! cp /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test_av_t3.json /home/xtest/projects/lavis_test/.cache/lavis/coco/annotations/coco_karpathy_test.json\n",
    "! python -m torch.distributed.run --nproc_per_node=2 evaluate.py --cfg-path lavis/projects/blip/eval/caption_coco_eval.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with 'v1', 'v2', 'v3', 'all' as the index\n",
    "index = ['Variant1', 'Variant2', 'variant3', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = [ \n",
    "    {\"Bleu_1\": 0.015837591785543434, \"Bleu_2\": 0.005047261847673106, \"Bleu_3\": 3.593811068943683e-08, \"Bleu_4\": 9.937291666199588e-11, \"METEOR\": 0.011182029008131854, \"ROUGE_L\": 0.06264322160445294, \"CIDEr\": 0.06621943582761985, \"SPICE\": 0.005555555555555555},\n",
    "    {\"Bleu_1\": 0.01185974449081995, \"Bleu_2\": 0.0032818616451593275, \"Bleu_3\": 1.7648915036669364e-08, \"Bleu_4\": 4.230529240005626e-11, \"METEOR\": 0.015179755321127022, \"ROUGE_L\": 0.05078594999423135, \"CIDEr\": 0.020553854682358347, \"SPICE\": 0.019707509994190228},\n",
    "    {\"Bleu_1\": 0.024965701374864986, \"Bleu_2\": 0.007976783356423727, \"Bleu_3\": 4.521728595275036e-08, \"Bleu_4\": 1.1180000582302765e-10, \"METEOR\": 0.019779703181870327, \"ROUGE_L\": 0.04954637378960567, \"CIDEr\": 0.020035869291716066, \"SPICE\": 0.012809011776753714},\n",
    "    {\"Bleu_1\": 0.018279280783872823, \"Bleu_2\": 0.005669268503294399, \"Bleu_3\": 2.338187352064745e-08, \"Bleu_4\": 4.918122090420213e-11, \"METEOR\": 0.015643991123115066, \"ROUGE_L\": 0.05778514028112853, \"CIDEr\": 0.03875663920494788, \"SPICE\": 0.014409479753455674}\n",
    "]\n",
    "\n",
    "\n",
    "base_df = pd.DataFrame(base_data, index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>3.593811e-08</td>\n",
       "      <td>9.937292e-11</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>0.066219</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>1.764892e-08</td>\n",
       "      <td>4.230529e-11</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>0.050786</td>\n",
       "      <td>0.020554</td>\n",
       "      <td>0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>4.521729e-08</td>\n",
       "      <td>1.118000e-10</td>\n",
       "      <td>0.019780</td>\n",
       "      <td>0.049546</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.012809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>2.338187e-08</td>\n",
       "      <td>4.918122e-11</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.057785</td>\n",
       "      <td>0.038757</td>\n",
       "      <td>0.014409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1    Bleu_2        Bleu_3        Bleu_4    METEOR   ROUGE_L  \\\n",
       "Variant1  0.015838  0.005047  3.593811e-08  9.937292e-11  0.011182  0.062643   \n",
       "Variant2  0.011860  0.003282  1.764892e-08  4.230529e-11  0.015180  0.050786   \n",
       "variant3  0.024966  0.007977  4.521729e-08  1.118000e-10  0.019780  0.049546   \n",
       "all       0.018279  0.005669  2.338187e-08  4.918122e-11  0.015644  0.057785   \n",
       "\n",
       "             CIDEr     SPICE  \n",
       "Variant1  0.066219  0.005556  \n",
       "Variant2  0.020554  0.019708  \n",
       "variant3  0.020036  0.012809  \n",
       "all       0.038757  0.014409  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_by_cadee_data = [ \n",
    "    {\"Bleu_1\": 0.009649627369113822, \"Bleu_2\": 0.003629175571340201, \"Bleu_3\": 2.7457669704252372e-08, \"Bleu_4\": 7.869198534355136e-11, \"METEOR\": 0.02036817717733883, \"ROUGE_L\": 0.0684106711438204, \"CIDEr\": 0.09594236243616086, \"SPICE\": 0.006666666666666667},\n",
    "    {\"Bleu_1\": 0.00920203716885307, \"Bleu_2\": 0.0032440259365530285, \"Bleu_3\": 0.0016571924530691179, \"Bleu_4\": 2.183708655563569e-07, \"METEOR\": 0.017255391677147486, \"ROUGE_L\": 0.04652365473116345, \"CIDEr\": 0.0042858619888026354, \"SPICE\": 0.006138392857142857},\n",
    "    {\"Bleu_1\": 0.01232615571778226, \"Bleu_2\": 0.00650699212299131, \"Bleu_3\": 0.004123864868527477, \"Bleu_4\": 5.199753021365646e-07, \"METEOR\": 0.026220913355182153, \"ROUGE_L\": 0.05002254233320028, \"CIDEr\": 0.013250897565259682, \"SPICE\": 0.038589705670451016},\n",
    "    {\"Bleu_1\": 0.011298531299361014, \"Bleu_2\": 0.005015458842038328, \"Bleu_3\": 0.0027879414922564053, \"Bleu_4\": 2.9344143364396227e-07, \"METEOR\": 0.02188463242522882, \"ROUGE_L\": 0.05695929283847704, \"CIDEr\": 0.056547108895361776, \"SPICE\": 0.01895267977490368}\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>2.745767e-08</td>\n",
       "      <td>7.869199e-11</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>0.095942</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>1.657192e-03</td>\n",
       "      <td>2.183709e-07</td>\n",
       "      <td>0.017255</td>\n",
       "      <td>0.046524</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>4.123865e-03</td>\n",
       "      <td>5.199753e-07</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>0.038590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>2.787941e-03</td>\n",
       "      <td>2.934414e-07</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>0.056547</td>\n",
       "      <td>0.018953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1    Bleu_2        Bleu_3        Bleu_4    METEOR   ROUGE_L  \\\n",
       "Variant1  0.009650  0.003629  2.745767e-08  7.869199e-11  0.020368  0.068411   \n",
       "Variant2  0.009202  0.003244  1.657192e-03  2.183709e-07  0.017255  0.046524   \n",
       "variant3  0.012326  0.006507  4.123865e-03  5.199753e-07  0.026221  0.050023   \n",
       "all       0.011299  0.005015  2.787941e-03  2.934414e-07  0.021885  0.056959   \n",
       "\n",
       "             CIDEr     SPICE  \n",
       "Variant1  0.095942  0.006667  \n",
       "Variant2  0.004286  0.006138  \n",
       "variant3  0.013251  0.038590  \n",
       "all       0.056547  0.018953  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadee_data_df = pd.DataFrame(fine_by_cadee_data, index=index)\n",
    "cadee_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_by_random_data = [ \n",
    "    {\"Bleu_1\": 0.01610694178754789, \"Bleu_2\": 0.006968155474369516, \"Bleu_3\": 4.3698657907650145e-08, \"Bleu_4\": 1.1364287701547716e-10, \"METEOR\": 0.01799097190352284, \"ROUGE_L\": 0.0572337835719442, \"CIDEr\": 0.07087138024191876, \"SPICE\": 0.015555555555555555},\n",
    "    {\"Bleu_1\": 0.018603469327587763, \"Bleu_2\": 0.008859801541945348, \"Bleu_3\": 0.004354903334184782, \"Bleu_4\": 4.7167368473933775e-07, \"METEOR\": 0.028330764747654776, \"ROUGE_L\": 0.07456899001315545, \"CIDEr\": 0.07019455541754788, \"SPICE\": 0.02654050992866782},\n",
    "    {\"Bleu_1\": 0.028291637270201814, \"Bleu_2\": 0.014347192731034259, \"Bleu_3\": 0.00906688046056752, \"Bleu_4\": 1.0177008600088224e-06, \"METEOR\": 0.030783404740711864, \"ROUGE_L\": 0.05770258054049655, \"CIDEr\": 0.011233988577120175, \"SPICE\": 0.03257798977915813},\n",
    "    {\"Bleu_1\": 0.024473596151826905, \"Bleu_2\": 0.011788714967354237, \"Bleu_3\": 0.006411136037711808, \"Bleu_4\": 5.830584422263194e-07, \"METEOR\": 0.027468376478660777, \"ROUGE_L\": 0.06641154197892804, \"CIDEr\": 0.054102270950162935, \"SPICE\": 0.02385927527433687}\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.016107</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>4.369866e-08</td>\n",
       "      <td>1.136429e-10</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>0.070871</td>\n",
       "      <td>0.015556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>4.354903e-03</td>\n",
       "      <td>4.716737e-07</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>0.074569</td>\n",
       "      <td>0.070195</td>\n",
       "      <td>0.026541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.028292</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>9.066880e-03</td>\n",
       "      <td>1.017701e-06</td>\n",
       "      <td>0.030783</td>\n",
       "      <td>0.057703</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.032578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.024474</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>6.411136e-03</td>\n",
       "      <td>5.830584e-07</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>0.066412</td>\n",
       "      <td>0.054102</td>\n",
       "      <td>0.023859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bleu_1    Bleu_2        Bleu_3        Bleu_4    METEOR   ROUGE_L  \\\n",
       "Variant1  0.016107  0.006968  4.369866e-08  1.136429e-10  0.017991  0.057234   \n",
       "Variant2  0.018603  0.008860  4.354903e-03  4.716737e-07  0.028331  0.074569   \n",
       "variant3  0.028292  0.014347  9.066880e-03  1.017701e-06  0.030783  0.057703   \n",
       "all       0.024474  0.011789  6.411136e-03  5.830584e-07  0.027468  0.066412   \n",
       "\n",
       "             CIDEr     SPICE  \n",
       "Variant1  0.070871  0.015556  \n",
       "Variant2  0.070195  0.026541  \n",
       "variant3  0.011234  0.032578  \n",
       "all       0.054102  0.023859  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random_data_df = pd.DataFrame(fine_by_random_data, index=index)\n",
    "random_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CIDEr  SPICE\n",
       "Variant1  0.066  0.006\n",
       "Variant2  0.021  0.020\n",
       "variant3  0.020  0.013\n",
       "all       0.039  0.014"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = base_df[['CIDEr', 'SPICE']]\n",
    "cadee_data_df = cadee_data_df[['CIDEr', 'SPICE']]\n",
    "random_data_df = random_data_df[['CIDEr', 'SPICE']]\n",
    "\n",
    "# round to 3 decimal places in python pandas\n",
    "base_df = base_df.round(3)\n",
    "cadee_data_df = cadee_data_df.round(3)\n",
    "random_data_df = random_data_df.round(3)\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {'Base': base_df, 'Random': random_data_df, 'CADEE': cadee_data_df}\n",
    "\n",
    "# Create a multi-index DataFrame by concatenating the dataframes along columns (axis=1)\n",
    "all_df = pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Base</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Random</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CADEE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variant1</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant2</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant3</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Base        Random         CADEE       \n",
       "          CIDEr  SPICE  CIDEr  SPICE  CIDEr  SPICE\n",
       "Variant1  0.066  0.006  0.071  0.016  0.096  0.007\n",
       "Variant2  0.021  0.020  0.070  0.027  0.004  0.006\n",
       "variant3  0.020  0.013  0.011  0.033  0.013  0.039\n",
       "all       0.039  0.014  0.054  0.024  0.057  0.019"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv with index\n",
    "# format the output of pandas dataframe to csv to keep the zero in the end of the number\n",
    "all_df.to_csv('../av_all_df.csv', index=True, float_format='%.3f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lavistest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
